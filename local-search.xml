<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Computer Vision Foundation -&gt; Image Processing2: Geometric Transformation</title>
    <link href="/2020/04/21/Computer-Vision-Fundation-Image-Processing2-Geometric-Transformation/"/>
    <url>/2020/04/21/Computer-Vision-Fundation-Image-Processing2-Geometric-Transformation/</url>
    
    <content type="html"><![CDATA[<p>In this post, another basic image operation is explored - Transformation.</p><p>This post is split into four sections:</p><ol><li>Mathematical and Computational Principle of Transformations</li><li>Practice with OpenCV in Python</li><li>Build <em>Translation</em> and <em>Rotation</em> Function From Scratch</li><li>(Option) Other Transformation Functions</li></ol><hr><h1 id="Principle-of-Transformation"><a href="#Principle-of-Transformation" class="headerlink" title="Principle of Transformation"></a>Principle of Transformation</h1><h3 id="Mathematics"><a href="#Mathematics" class="headerlink" title="Mathematics"></a>Mathematics</h3><p>In general, a transformation of a point \(\mathbf{p}\), \(\begin{pmatrix} v &amp; w \end{pmatrix}\) to another point \(\mathbf{q}\), \(\begin{pmatrix} x &amp; y \end{pmatrix}\) is given by<br>\[\mathbf{q} = \mathbf{R}\mathbf{p} + \mathbf{T}.\]<br>Explicitly,<br>\[<br>\begin{bmatrix} x \\ y \end{bmatrix} = \begin{bmatrix} \omega_1 &amp; \omega_2 \\ \omega_3 &amp; \omega_4 \end{bmatrix} \begin{bmatrix} v \\ w \end{bmatrix} + \begin{bmatrix} t_1 \\ t_2 \end{bmatrix}.<br>\]<br>where the \(\mathbf{R}\) and \(\mathbf{T}\) denote rotation and translation matrices respectively.</p><p>To make the expression more compact, we can write it as<br>\[<br>\begin{bmatrix} x \\ y \end{bmatrix} = \begin{bmatrix} \omega_1 &amp; \omega_2 &amp; t_1\\ \omega_3 &amp; \omega_4 &amp; t_2 \end{bmatrix} \begin{bmatrix} v \\ w \\ 1 \end{bmatrix}.<br>\]</p><p>A quick method to determine the transformation matrix is to consider the changes of unit vectors \(\hat{i}\) and \(\hat{j}\).</p><p>For example, if the \(\mathbf{R}\) is an identity matrix and \(\mathbf{T} = \mathbf{0}\) (i.e. no transformation), then the equation is<br>\[<br>\begin{bmatrix} x \\ y \end{bmatrix} = \begin{bmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{bmatrix} \begin{bmatrix} v \\ w \end{bmatrix}.<br>\]<br>Another way to look at this equation is<br>\[<br>\begin{bmatrix} x \\ y \end{bmatrix} = v \begin{bmatrix} 1 \\ 0 \end{bmatrix} + w \begin{bmatrix} 0 \\ 1 \end{bmatrix},<br>\]<br>which means that \(v\) and \(w\) are values to scale up the unit vectors \(\hat{i}\) and \(\hat{j}\). Therefore, any transformation of the vector \(\begin{bmatrix} v \\ w \end{bmatrix}\) can be regards as the transformation of the entire vector space formed by \(\hat{i}\) and \(\hat{j}\).</p><p><img src="rotation.png" srcset="/img/loading.gif" alt="rotation"><br>Take rotation as an example, if \(\hat{i}\) and \(\hat{j}\) are rotated anti-clockwise by an angle \(\theta\), then \(\hat{i}\) becomes \(\begin{bmatrix} cos(\theta) \\ sin(\theta) \end{bmatrix}\) and \(\hat{j}\) becomes \(\begin{bmatrix} -sin(\theta) \\ cos(\theta) \end{bmatrix}\). Thus, the equation is<br>\[<br>\begin{bmatrix} x \\ y \end{bmatrix} = v \begin{bmatrix} cos(\theta) \\ sin(\theta) \end{bmatrix} + w \begin{bmatrix} -sin(\theta) \\ cos(\theta) \end{bmatrix}.<br>\]<br>Therefore, in the general equation, we should use the matrix<br>\[ \begin{bmatrix} \cos(\theta) &amp; -sin(\theta) &amp; 0\\ sin(\theta) &amp; cos(\theta) &amp; 0 \end{bmatrix}. \]<br>Other transformation matrix can be obtained in the same manner.</p><h3 id="Computation"><a href="#Computation" class="headerlink" title="Computation"></a>Computation</h3><p>Except the expression in <strong>Mathematics</strong>, sometimes square matrix can be used.<br>\[<br>\begin{bmatrix} x \\ y \\ 1\end{bmatrix} = \begin{bmatrix} \omega_1 &amp; \omega_2 &amp; t_1\\ \omega_3 &amp; \omega_4 &amp; t_2 \\ 0 &amp; 0 &amp; 1\end{bmatrix} \begin{bmatrix} v \\ w \\ 1\end{bmatrix},<br>\]<br>or if row vectors are used<br>\[<br>\begin{bmatrix} x &amp; y &amp; 1\end{bmatrix} = \begin{bmatrix} v &amp; w &amp; 1\end{bmatrix} \begin{bmatrix} \omega_1 &amp; \omega_3 &amp; 0\\ \omega_2 &amp; \omega_4 &amp; 0 \\ t_1 &amp; t_2 &amp; 1\end{bmatrix}.<br>\]<br>The matrix should be obtained using the same manner discussed in last section.</p><p>One issue to consider when processing images in computer is that the origin of the image does not locate at the centre of the image, but at the top-left corner. It works for translation and resizing. But converting to Cartesian coordinates is necessary before rotation or shearing.<br><img src="coordinate.png" srcset="/img/loading.gif" alt="coordinate"></p><p>Therefore, rotation or shearing requires three steps:</p><ol><li>Convert from image coordinates to Cartesian coordinates</li><li>Perform rotation or shearing</li><li>Convert the results back to image coordinates</li></ol><p>It is not hard to realise that for a \((M \times N)\) matrix, the origin of the image space locates at \(-\frac{N}{2}, \frac{M}{2}\). Thus, the transformation can be calculated from<br>\[<br>\begin{bmatrix} x &amp; y &amp; 1\end{bmatrix} = \begin{bmatrix} v &amp; w &amp; 1 \end{bmatrix} \begin{bmatrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; -1 &amp; 0 \\ -0.5N &amp; 0.5M &amp; 1 \end{bmatrix} \begin{bmatrix} \mathbf{R}^T &amp; \mathbf{0} \\ \mathbf{T}^T &amp; 1 \end{bmatrix} \begin{bmatrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; -1 &amp; 0 \\ 0.5N &amp; 0.5M &amp; 1 \end{bmatrix}.<br>\]</p><h4 id="Aside"><a href="#Aside" class="headerlink" title="Aside"></a>Aside</h4><p>One technical nuance that we need to consider is whether forward or backward mapping should be used after transformation. Intuitively, forward mapping is the procedure to obtain the transformed images. However, couple of problems can occur.<br><img src="forward_mapping.png" srcset="/img/loading.gif" alt="forward"></p><ol><li>It can result pixels outside the image boundary.</li><li>Complex transforms can map several input pixels to the same output pixel.</li><li>The pixel value of the output pixel cannot be obtained simply. As shown in the diagram, the pixel value of the mapped pixel should be interpolated from nearby pixels. Thus, all the mapped pixels have to be computed first.</li></ol><p>Backward mapping, on the other side, find the corresponding point of the mapped pixel on the original image.<br><img src="backward_mapping.png" srcset="/img/loading.gif" alt="backward"><br>Then, the pixel value can be calculated using the nearby pixels on the original image. Therefore, it costs less computationally.</p><p>As we need to interpolate the pixel values, An interpolation mechanism needs selecting. Normally, bilinear interpolation is preferred. OpenCV uses bilinear interpolation as well.</p><hr><h1 id="Practice-with-OpenCV-in-Python"><a href="#Practice-with-OpenCV-in-Python" class="headerlink" title="Practice with OpenCV in Python"></a>Practice with OpenCV in Python</h1><h3 id="Documentation"><a href="#Documentation" class="headerlink" title="Documentation"></a>Documentation</h3><h4 id="General-Transformation-Method-Affine-Transformation"><a href="#General-Transformation-Method-Affine-Transformation" class="headerlink" title="General Transformation Method (Affine Transformation)"></a>General Transformation Method (Affine Transformation)</h4><pre><code>dst = cv2.warpAffine(src, M, dsize[, dst[, flags[, borderMode[, borderValue]]]])</code></pre><p><strong>src</strong> -&gt; (compulsory) Source image.<br><strong>dst</strong> -&gt; Destination image.<br><strong>M</strong> -&gt; (compulsory) \(2 \times 3\) transformation matrix.<br><strong>dsize</strong> -&gt; (compulsory) Destination image size.<br><strong>flages</strong> -&gt; (optional) Combination of interpolation methods (Conduct the last post <em>Resize</em>). <strong>INTER_LINEAR</strong> is used by <em>default</em><br><em>-Addition-</em><br><strong>borderMode</strong> and <strong>borderValue</strong> take care of the border of the destination image. For example, if <strong>borderMode=BORDER_TRANSPARENT</strong>, then the pixels in the destination image corresponding to the “outliers” in the source image are not modified by the function.</p><p><em>Note</em> Unlike what I stated in <strong>Computation</strong>, <strong>M</strong> in this function is a \(2 \times 3\) matrix as stated in <strong>Mathematics</strong>.</p><h4 id="Rotation-Matrix"><a href="#Rotation-Matrix" class="headerlink" title="Rotation Matrix"></a>Rotation Matrix</h4><p>As mentioned in <strong>Computation</strong>, for rotation and shearing, we need to convert the coordinate system first. In OpenCV, for rotation, this can easily be done using <code>getRotationMatrix2D</code>.</p><pre><code>R = cv2.getRotationMatrix2D(center, angle, scale)</code></pre><p><strong>center</strong> -&gt; (compulsory) Center of the rotation in the source image.<br><strong>angle</strong> -&gt; (compulsory) Rotation angle in <em>degrees</em>. Positive values mean anti-clockwise rotation (the coordinate origin is assumed to be the top-left corner).<br><strong>scale</strong> -&gt; (compulsory) Isotropic scale factor.<br>This will give the rotation matrix \(\mathbf{R}\), which can then be used in <code>warpAffine</code>. As shown in <strong>Computation</strong>, to convert the coordinate system to Cartesian, the <code>center=(cols/2, rows/2)</code>, where <code>cols</code> and <code>rows</code> can be obtained from <code>image.shape</code></p><h4 id="Shearing-Matrix"><a href="#Shearing-Matrix" class="headerlink" title="Shearing Matrix"></a>Shearing Matrix</h4><p>To implement the shearing operation, we have to construct the matrix ourselves with the procedure stated in <strong>Computation</strong>. Notice that truncated and transverse matrix should be constructed to match OpenCV convention. Details in example code.</p><h3 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h3><pre><code>import numpy as npimport cv2name = image_nameimg = cv2.imread(&#39;./{}.jpg&#39;.format(name), cv2.IMREAD_UNCHANGED)rows, cols, _ = img.shape# TranslationT = np.array(([1, 0, 100], [0, 1, 50]), dtype=np.float32)# RotationR = cv2.getRotationMatrix2D((cols/2, rows/2), 45, 1)# Shearingconvert = np.array(([1, 0, 0], [0, -1, 0], [cols/2, rows/2, 1]), dtype=np.float32)inverse = np.array(([1, 0, 0], [0, -1, 0], [-cols/2, rows/2, 1]), dtype=np.float32)S = np.array(([1, 0, 0], [0.5, 1, 0], [0, 0, 1]), dtype=np.float32)  # unit vector (0, 1) to (0.5, 1), shear to x direction# To match OpenCV conventionS = inverse@S@convert[:, :-1]S = np.transpose(S)translated = cv2.warpAffine(img, T, (cols, rows))rotated = cv2.warpAffine(img, R, (cols, rows))sheared = cv2.warpAffine(img, S, (cols, rows))cv2.imshow(&quot;Translated image&quot;, translated)cv2.imshow(&quot;Rotated image&quot;, rotated)cv2.imshow(&quot;Sheared image&quot;, sheared)# Press &#39;s&#39; for saving the imagek = cv2.waitKey(0)if k == 27:         # wait for ESC key to exit    cv2.destroyAllWindows()elif k == ord(&#39;s&#39;): # wait for &#39;s&#39; key to save and exit    cv2.imwrite(&quot;Translated.jpg&quot;,translated)    cv2.imwrite(&quot;Rotated.jpg&quot;,rotated)    cv2.imwrite(&quot;Sheared.jpg&quot;,sheared)    cv2.destroyAllWindows()</code></pre><p>Example results are shown below:<br><strong>The original image</strong> (From last post)<br><img src="flower_Resized_image.jpg" srcset="/img/loading.gif" alt="small"></p><p><strong>Translation</strong><br><img src="flower_Translated.jpg" srcset="/img/loading.gif" alt="t"></p><p><strong>Rotation</strong><br><img src="flower_Rotated.jpg" srcset="/img/loading.gif" alt="r"></p><p><strong>Shearing</strong><br><img src="flower_Sheared.jpg" srcset="/img/loading.gif" alt="s"></p><hr><h1 id="Build-Each-Transformation-Function-From-Scratch-TODO"><a href="#Build-Each-Transformation-Function-From-Scratch-TODO" class="headerlink" title="Build Each Transformation Function From Scratch (TODO)"></a>Build Each Transformation Function From Scratch (TODO)</h1><p>Shearing function has already been built in the last section.</p><hr><h1 id="Option-Other-Transformation-Functions-TODO"><a href="#Option-Other-Transformation-Functions-TODO" class="headerlink" title="(Option) Other Transformation Functions (TODO)"></a>(Option) Other Transformation Functions (TODO)</h1><hr><h1 id="Acknowledgement"><a href="#Acknowledgement" class="headerlink" title="Acknowledgement"></a>Acknowledgement</h1><p>The creation of this post is inspired by <strong>Datawhale</strong>.</p><hr><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li>Reed, N., 2020. Rotations And Infinitesimal Generators – Nathan Reed’S Coding Blog. [online] Reedbeta.com. Available at: <a href="http://reedbeta.com/blog/rotations-and-infinitesimal-generators/" target="_blank" rel="noopener">http://reedbeta.com/blog/rotations-and-infinitesimal-generators/</a> [Accessed 22 April 2020].</li><li>Lohninger, H., 2020. Java Programming Course - Coordinates. [online] Vias.org. Available at: <a href="http://www.vias.org/javacourse/chap04_10.html" target="_blank" rel="noopener">http://www.vias.org/javacourse/chap04_10.html</a> [Accessed 22 April 2020].</li><li>Blog.csdn.net. 2020. 图像变换——向前映射和向后映射_人工智能_薇洛的打火机-CSDN博客. [online] Available at: <a href="https://blog.csdn.net/glorydream2015/article/details/44873703" target="_blank" rel="noopener">https://blog.csdn.net/glorydream2015/article/details/44873703</a> [Accessed 22 April 2020].</li><li>Engr.case.edu. 2020. [online] Available at: <a href="http://engr.case.edu/merat_francis/eecs490f07/lectures/lecture4.pdf" target="_blank" rel="noopener">http://engr.case.edu/merat_francis/eecs490f07/lectures/lecture4.pdf</a> [Accessed 22 April 2020].</li><li>Docs.opencv.org. 2020. Geometric Image Transformations — Opencv 2.4.13.7 Documentation. [online] Available at: <a href="https://docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html?highlight=warpaffine" target="_blank" rel="noopener">https://docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html?highlight=warpaffine</a> [Accessed 22 April 2020].</li></ol><hr>]]></content>
    
    
    
    <tags>
      
      <tag>Computer</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Computer Vision Foundation -&gt; Image Processing1: Digital Image Interpolation</title>
    <link href="/2020/04/19/Computer-Vision-Fundation-Image-Processing1-Digital-Image-Interpolation/"/>
    <url>/2020/04/19/Computer-Vision-Fundation-Image-Processing1-Digital-Image-Interpolation/</url>
    
    <content type="html"><![CDATA[<p>To fully understand computer vision, learning image processing is inevitable. One basic operation is to resize the images. When enlarging a small image, the resulted image may have jagged pixel edges. Image interpolation is to add a few pixels and manipulate their value in purpose so that the resulted image looks smoother.</p><p>This post is split into four sections:</p><ol><li>Two Basic Image Interpolation Algorithm</li><li>Practice with OpenCV in Python</li><li>Build <em>Resize</em> Function From Scratch</li><li>(Option) Other Interpolation Algorithm</li></ol><hr><h1 id="Two-Basic-Image-Interpolation-Algorithm"><a href="#Two-Basic-Image-Interpolation-Algorithm" class="headerlink" title="Two Basic Image Interpolation Algorithm"></a>Two Basic Image Interpolation Algorithm</h1><h3 id="Nearest-neighbour-interpolation"><a href="#Nearest-neighbour-interpolation" class="headerlink" title="Nearest-neighbour interpolation"></a>Nearest-neighbour interpolation</h3><p>When the image size increases, the extra pixels will use the same value as their nearest neighbour.<br><img src="/images/Nearest1.png" srcset="/img/loading.gif" alt="Nearest"><br>This is the simplest method. However, it is not hard to realise that this approach is problematic as it preserves the same resolution as the small image.</p><h3 id="Bilinear-interpolation"><a href="#Bilinear-interpolation" class="headerlink" title="Bilinear interpolation"></a>Bilinear interpolation</h3><p>Bilinear interpolation tries to estimate the new pixel values using information from their neighbours. Normally, linear relations are assumed in both \(x\) and \(y\) directions, namely bilinear relation. Hopefully, it will give a smoother enlarged image than <strong>Nearest-neighbour interpolation</strong>.</p><p>Typical derivation follows the logic that the enlargement should have bilinear relation and it should work to give a smoother image. Here, I decided to follow the opposite route. By assuming the resulted image is continuous and smooth, we can obtain the <strong>Bilinear interpolation</strong> without assuming bilinear relation at the first place. The full derivation will be shown in <em>Appendix</em>. Two routes are essentially equivalent.<br><img src="/images/Bilinear.png" srcset="/img/loading.gif" alt="Bilinear"><br>The equation is<br>\[<br>  f(x, y) = \frac{(x_2 - x)(y_2-y)}{(x_2 - x_1)(y_2-y_1)}f(Q_{11}) + \frac{(x - x_1)(y_2-y)}{(x_2 - x_1)(y_2-y_1)}f(Q_{21}) + \frac{(x_2 - x)(y-y_1)}{(x_2 - x_1)(y_2-y_1)}f(Q_{12}) + \frac{(x - x_1)(y-y_1)}{(x_2 - x_1)(y_2-y_1)}f(Q_{22}).<br>\]<br>Or in matrix form,<br>$$<br>  f(x, y) = \frac{1}{(x_2 - x_1)(y_2-y_1)} \begin{bmatrix} (x_2-x) &amp; (x-x_1) \end{bmatrix} \begin{bmatrix} f(Q_{11}) &amp; f(Q_{12}) \\ f(Q_{21}) &amp; f(Q_{22}) \end{bmatrix} \begin{bmatrix} (y_2-y) \\ (y-y_1) \end{bmatrix}.<br>$$</p><hr><h1 id="Practice-with-OpenCV-in-Python"><a href="#Practice-with-OpenCV-in-Python" class="headerlink" title="Practice with OpenCV in Python"></a>Practice with OpenCV in Python</h1><h3 id="Documentation"><a href="#Documentation" class="headerlink" title="Documentation"></a>Documentation</h3><p>Despite the maths looks complicated, the implementation is straightforward using OpenCV and Python.</p><pre><code>dst = cv2.resize(src, dsize[, dst[, fx[, fy[, interpolation]]]])</code></pre><p><strong>src</strong> -&gt; (compulsory) Source image.<br><strong>dst</strong> -&gt; Destination image.<br><strong>dsize</strong> -&gt; (compulsory) Destination image size. If it is \(0\), it is computed as:</p><pre><code>  dsize = Size(round(fx*src.cols), round(fy*src.rows))</code></pre><p><strong>fx</strong> -&gt; (optional) Scale factor along the horizontal axis. When it is \(0\), it is computed as:</p><pre><code>  (double)dsize.width/src.cols</code></pre><p><strong>fy</strong> -&gt; (optional) Scale factor along the vertical axis. When it is \(0\), it is computed as:</p><pre><code>  (double)dsize.height/src.rows</code></pre><p><strong>interpolation</strong> -&gt; (optional) Interpolation method:<br>  <strong>INTER_NEAREST</strong> - a nearest-neighbour interpolation<br>  <strong>INTER_LINEAR</strong> - a bilinear interpolation (used by <em>default</em>)<br>  <em>-Addition-</em><br>  <strong>INTER_AREA</strong> - resampling using pixel area relation. It may be a preferred method for image decimation, as it gives moire’-free results. But when the image is zoomed, it is similar to the <strong>INTER_NEAREST</strong> method.<br>  <strong>INTER_CUBIC</strong> - a bicubic interpolation over 4x4 pixel neighbourhood<br>  <strong>INTER_LANCZOS4</strong> - a Lanczos interpolation over 8x8 pixel neighbourhood</p><p><em>Note</em> that, normally, <strong>INTER_AREA</strong> is used when scaling down the image. Otherwise, <strong>INTER_CUBIC</strong> and <strong>INTER_LINEAR</strong> are good choices. But <strong>INTER_CUBIC</strong> is a bit slow.</p><h3 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h3><pre><code>import cv2img = cv2.imread(image_name, cv2.IMREAD_UNCHANGED)  # replace with your image_namescale_percent = 5       # percent of original sizewidth = int(img.shape[1] * scale_percent / 100)height = int(img.shape[0] * scale_percent / 100)dim = (width, height)# scale down the imageresized = cv2.resize(img, dim, interpolation = cv2.INTER_LINEAR)fx = 3fy = 3# scale up the resized imageresized1 = cv2.resize(resized, dsize=None, fx=fx, fy=fy, interpolation = cv2.INTER_NEAREST)resized2 = cv2.resize(resized, dsize=None, fx=fx, fy=fy, interpolation = cv2.INTER_LINEAR)# display the resultscv2.imshow(&quot;Resized image&quot;, resized)cv2.imshow(&quot;INTER_NEAREST image&quot;, resized1)cv2.imshow(&quot;INTER_LINEAR image&quot;, resized2)# Press &#39;s&#39; for saving the imagek = cv2.waitKey(0)if k == 27:         # wait for ESC key to exit    cv2.destroyAllWindows()elif k == ord(&#39;s&#39;): # wait for &#39;s&#39; key to save and exit    cv2.imwrite(&quot;Resized_image.jpg&quot;,resized)    cv2.imwrite(&quot;INTER_NEAREST_image.jpg&quot;,resized1)    cv2.imwrite(&quot;INTER_LINEAR_image.jpg&quot;,resized2)    cv2.destroyAllWindows()</code></pre><p>Example results are shown below:<br><strong>Scale down the original image by 95% using Bilinear interpolation</strong><br><img src="/images/Resized_image.jpg" srcset="/img/loading.gif" alt="small"></p><p><strong>Scale up the resized image by 30% using Nearest-neighbour interpolation</strong><br><img src="/images/INTER_NEAREST_image.jpg" srcset="/img/loading.gif" alt="nearest_image"></p><p><strong>Scale up the resized image by 30% using Bilinear interpolation</strong><br><img src="/images/INTER_LINEAR_image.jpg" srcset="/img/loading.gif" alt="bilinear_image"><br>It is clear that the result of the Bilinear interpolation is much smoother than it of the Nearest-neighbour interpolation.</p><hr><h1 id="Build-Resize-Function-From-Scratch-TODO"><a href="#Build-Resize-Function-From-Scratch-TODO" class="headerlink" title="Build Resize Function From Scratch (TODO)"></a>Build <em>Resize</em> Function From Scratch (TODO)</h1><hr><h1 id="Option-Other-Interpolation-Algorithm-TODO"><a href="#Option-Other-Interpolation-Algorithm-TODO" class="headerlink" title="(Option) Other Interpolation Algorithm (TODO)"></a>(Option) Other Interpolation Algorithm (TODO)</h1><hr><h1 id="Appendix-Derivation-of-Bilinear-interpolation"><a href="#Appendix-Derivation-of-Bilinear-interpolation" class="headerlink" title="Appendix - Derivation of Bilinear interpolation"></a>Appendix - Derivation of Bilinear interpolation</h1><p><img src="/images/Bilinear.png" srcset="/img/loading.gif" alt="Bilinear"><br>Assumptions: The image is smooth in any directions; \(Q_{11}\), \(Q_{12}\), \(Q_{21}\), \(Q_{22}\), \(R_1\), \(R_2\) and \(p\) are close enough.</p><p>Follow by the assumptions, we have<br>\[<br>f(R_1) = f(p) - \frac{\partial f(p)}{\partial y}\Bigr\rvert_{x} (y-y_1);<br>f(R_2) = f(p) + \frac{\partial f(p)}{\partial y}\Bigr\rvert_{x} (y_2-y).<br>\]<br>Then,<br>\[<br>f(Q_{11}) = f(R_1) - \frac{\partial f(R_1)}{\partial x}\Bigr\rvert_{y_1} (x-x_1); f(Q_{21}) = f(R_1) + \frac{\partial f(R_1)}{\partial x}\Bigr\rvert_{y_1} (x_2-x);<br>\]<br>\[<br>f(Q_{12}) = f(R_2) - \frac{\partial f(R_2)}{\partial x}\Bigr\rvert_{y_2} (x-x_1); f(Q_{22}) = f(R_2) + \frac{\partial f(R_2)}{\partial x}\Bigr\rvert_{y_2} (x_2-x).<br>\]<br>Substituting \(f(R_1)\) and \(f(R_2)\) into the equations, we find that<br>\[<br>f(Q_{11}) = f(p) - \frac{\partial f(p)}{\partial y}\Bigr\rvert_{x} (y-y_1) - \frac{\partial f(p)}{\partial x}\Bigr\rvert_{y_1} (x-x_1) + \frac{\partial^2 f(p)}{\partial x \partial y}\Bigr\rvert_{y_1} (x-x_1) (y-y_1),<br>\]<br>the last term equals \(0\) as the function is evaluated at \(y=y_1\). Therefore, we have<br>\[<br>f(Q_{11}) = f(p) - \frac{\partial f(p)}{\partial y}\Bigr\rvert_{x} (y-y_1) - \frac{\partial f(p)}{\partial x}\Bigr\rvert_{y_1} (x-x_1);<br>\]<br>\[<br>f(Q_{21}) = f(p) - \frac{\partial f(p)}{\partial y}\Bigr\rvert_{x} (y-y_1) + \frac{\partial f(p)}{\partial x}\Bigr\rvert_{y_1} (x_2-x);<br>\]<br>\[<br>f(Q_{12}) = f(p) + \frac{\partial f(p)}{\partial y}\Bigr\rvert_{x} (y_2-y) - \frac{\partial f(p)}{\partial x}\Bigr\rvert_{y_2} (x-x_1);<br>\]<br>\[<br>f(Q_{22}) = f(p) + \frac{\partial f(p)}{\partial y}\Bigr\rvert_{x} (y_2-y) + \frac{\partial f(p)}{\partial x}\Bigr\rvert_{y_2} (x_2-x).<br>\]</p><p>By rearranging the equations, we can find that<br>\[<br>\frac{\partial f(p)}{\partial y}\Bigr\rvert_{x} (y-y_1) = f(p) - f(Q_{11}) - \frac{\partial f(p)}{\partial x}\Bigr\rvert_{y_1} (x-x_1) = f(p) - f(Q_{21}) + \frac{\partial f(p)}{\partial x}\Bigr\rvert_{y_1} (x_2-x);<br>\]<br>\[<br>\frac{\partial f(p)}{\partial y}\Bigr\rvert_{x}(y_2-y) = f(Q_{12}) - f(p) +  \frac{\partial f(p)}{\partial x}\Bigr\rvert_{y_2} (x-x_1) = f(Q_{22}) - f(p) - \frac{\partial f(p)}{\partial x}\Bigr\rvert_{y_2} (x_2-x).<br>\]<br>Then,<br>\[<br>\frac{\partial f(p)}{\partial x}\Bigr\rvert_{y_1} = \frac{f(Q_{21}) - f(Q_{11})}{x_2-x_1};<br>\]<br>\[<br>\frac{\partial f(p)}{\partial x}\Bigr\rvert_{y_2} = \frac{f(Q_{22}) - f(Q_{12})}{x_2-x_1}.<br>\]</p><p>Substituting the above equations back, we can fine \(\frac{\partial f(p)}{\partial y}\Bigr\rvert_{x}\) as<br>\[<br>\frac{\partial f(p)}{\partial y}\Bigr\rvert_{x} = \frac{f(p) - f(Q_{11})}{y-y_1} - \frac{x-x_1}{y-y_1}\frac{f(Q_{21}) - f(Q_{11})}{x_2-x_1} = \frac{f(Q_{12}) - f(p)}{y_2-y} - \frac{x-x_1}{y_2-y}\frac{f(Q_{22}) - f(Q_{12})}{x_2-x_1}.<br>\]</p><p>Rearrange to get \(f(p)\). Finally, we have the <strong>Bilinear relation</strong> that we want.<br>\[<br>f(p) = \frac{(x_2 - x)(y_2-y)}{(x_2 - x_1)(y_2-y_1)}f(Q_{11}) + \frac{(x - x_1)(y_2-y)}{(x_2 - x_1)(y_2-y_1)}f(Q_{21}) + \frac{(x_2 - x)(y-y_1)}{(x_2 - x_1)(y_2-y_1)}f(Q_{12}) + \frac{(x - x_1)(y-y_1)}{(x_2 - x_1)(y_2-y_1)}f(Q_{22}).<br>\]</p><hr><h1 id="Acknowledgement"><a href="#Acknowledgement" class="headerlink" title="Acknowledgement"></a>Acknowledgement</h1><p>The creation of this post is inspired by <strong>Datawhale</strong>.</p><hr><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li>Blog.csdn.net. 2020. Opencv框架与图像插值算法_网络_Weixin_39940512的博客-CSDN博客. [online] Available at: <a href="https://blog.csdn.net/weixin_39940512/article/details/105343418" target="_blank" rel="noopener">https://blog.csdn.net/weixin_39940512/article/details/105343418</a> [Accessed 20 April 2020].</li><li>Angel, A., 2020. Nearest Neighbor Interpolation. [online] Imageeprocessing.com. Available at: <a href="https://www.imageeprocessing.com/2017/11/nearest-neighbor-interpolation.html" target="_blank" rel="noopener">https://www.imageeprocessing.com/2017/11/nearest-neighbor-interpolation.html</a> [Accessed 19 April 2020].</li><li>En.wikipedia.org. 2020. Bilinear Interpolation. [online] Available at: <a href="https://en.wikipedia.org/wiki/Bilinear_interpolation" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Bilinear_interpolation</a> [Accessed 20 April 2020].</li><li>Opencv.org.cn. 2020. Geometric Image Transformations — Opencv 2.3.2 Documentation. [online] Available at: <a href="http://www.opencv.org.cn/opencvdoc/2.3.2/html/modules/imgproc/doc/geometric_transformations.html?highlight=resize#cv.Resize" target="_blank" rel="noopener">http://www.opencv.org.cn/opencvdoc/2.3.2/html/modules/imgproc/doc/geometric_transformations.html?highlight=resize#cv.Resize</a> [Accessed 20 April 2020].</li><li>Photo by Viktor Mogilat on Unsplash.</li><li>Opencv-python-tutroals.readthedocs.io. 2020. Getting Started With Images — Opencv-Python Tutorials 1 Documentation. [online] Available at: <a href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_image_display/py_image_display.html" target="_blank" rel="noopener">https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_image_display/py_image_display.html</a> [Accessed 20 April 2020].</li></ol><hr>]]></content>
    
    
    
    <tags>
      
      <tag>Computer</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Quarantine-Day-2|隔离第二天</title>
    <link href="/2020/04/16/Quarantine-Day-2-%E9%9A%94%E7%A6%BB%E7%AC%AC%E4%BA%8C%E5%A4%A9/"/>
    <url>/2020/04/16/Quarantine-Day-2-%E9%9A%94%E7%A6%BB%E7%AC%AC%E4%BA%8C%E5%A4%A9/</url>
    
    <content type="html"><![CDATA[<p>Today is the second day of my quarantine session. Due to the unespected situation and my original career path, I decided to accelerate my job hunting. But when I begin, I am a little comfused and upset. I understand I need sometime to digest a new way of thinking. I might be immature and naive. I almost spent the whole day in looking for information and filling up different files. </p><p>To summarise some points that I obtained today, I need to firm my essential coding skills. I did not learn programming until last year, but it cannot be my excuse. Also, I need to find out how I can use what I know to make profit. This year, I learned about Computer Vision, Graphics, VR/AR. I enjoyed learning new stuff but worried little about what I can do with these cutting-edge technologies. Also, I need to link these back to the fundamental data sturctures and popular libraries. </p><p>Hope today’s work can help me make my mind!</p>]]></content>
    
    
    
    <tags>
      
      <tag>Diary</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Weight Record</title>
    <link href="/2020/04/15/Weight-Record/"/>
    <url>/2020/04/15/Weight-Record/</url>
    
    <content type="html"><![CDATA[<p><em>Goal</em>: 70kg</p><p>One-punch Man Training:</p><ol><li>Push-ups - 100 times</li><li>Sit-ups - 100 times</li><li>Squats - 100 times</li><li>Jogging - 10km</li></ol><hr><h1 id="Date-2020-04-15"><a href="#Date-2020-04-15" class="headerlink" title="Date: 2020/04/15"></a>Date: 2020/04/15</h1><p>Weight: 77kg<br>Activity: N/A</p><h1 id="Date-2020-04-16"><a href="#Date-2020-04-16" class="headerlink" title="Date: 2020/04/16"></a>Date: 2020/04/16</h1><p>Weight: 77kg<br>Activity: 50% of 1 - 3</p><h1 id="Date-2020-04-17"><a href="#Date-2020-04-17" class="headerlink" title="Date: 2020/04/17"></a>Date: 2020/04/17</h1><p>Weight: 77kg<br>Activity: 50% of 1 - 3</p><h1 id="Date-2020-04-20"><a href="#Date-2020-04-20" class="headerlink" title="Date: 2020/04/20"></a>Date: 2020/04/20</h1><p>Weight: 77kg<br>Activity: 50% of 1 - 3</p><h1 id="Date-2020-04-21"><a href="#Date-2020-04-21" class="headerlink" title="Date: 2020/04/21"></a>Date: 2020/04/21</h1><p>Weight: 77kg<br>Activity: 50% of 1 - 3</p>]]></content>
    
    
    
    <tags>
      
      <tag>Diary</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Quarantine Day 1|隔离第一天</title>
    <link href="/2020/04/15/Quarantine-Day-1-%E9%9A%94%E7%A6%BB%E7%AC%AC%E4%B8%80%E5%A4%A9/"/>
    <url>/2020/04/15/Quarantine-Day-1-%E9%9A%94%E7%A6%BB%E7%AC%AC%E4%B8%80%E5%A4%A9/</url>
    
    <content type="html"><![CDATA[<p>Today is 2020/04/15. I have arrived in Shanghai and begun my quarantine life. As I have two upcoming deadlines, I will dedicate my time on two topics during the quarantine period. One is <strong>volumetric transform</strong>, the other is <strong>using asymmetric vibration to induce sensation of force</strong>. Because of UCL school policy, I am not allowed to show my coursework in detail. I will only show briefly the literature review and my understandings of the second topics. Later, I will probably show you the results of the first topics. Also, I will make a series of topics in <strong>Computer Vision</strong> when I do my revision during and after the quarantine period.</p><p>One thing I found intriguing in the area of VR was haptics. Nowadays, there are many ways to use human hands to interact with virtual objects. They are easier and more intuitive than the normal VR controllers. The cheapest way is the hand tracking using cameras. For example, Oculus has announced that they will include hand tracking in the latest Oculus Quest; Leap Motion has worked in this field for a decade. Despite, using visual information is cheap, it is not always reliable as the hand position, orientation, light and occlusion conditions are constantly varying. Haptics glove is one alternative. Data-driven gloves can precisely track our hand and fingers. Plus, with the available data, force feedback haptics can be built.</p><p>Personally, I believed that force feedback haptic glove is the future of VR interaction. Users cannot only touch, hold and move virtual objects, but also feel the shape, reaction force, texture or even temperature of the virtual objects. Is not a fascinating idea?</p>]]></content>
    
    
    
    <tags>
      
      <tag>Diary, Computer</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Create A Blog|创建博客</title>
    <link href="/2020/04/13/Create-A-Blog-%E5%88%9B%E5%BB%BA%E5%8D%9A%E5%AE%A2/"/>
    <url>/2020/04/13/Create-A-Blog-%E5%88%9B%E5%BB%BA%E5%8D%9A%E5%AE%A2/</url>
    
    <content type="html"><![CDATA[<p>Today is 2020/04/13, I will be on the plane to China in about 10 hours. I heard about how writing blog would help improve IT skills for a long time, but did not know when and how to start. Now I finally made my mind to create a blog. For thhe processes, I conducted “<a href="https://www.bilibili.com/video/BV1Yb411a7ty?from=search&amp;seid=13126380643235482353&quot;" target="_blank" rel="noopener">https://www.bilibili.com/video/BV1Yb411a7ty?from=search&amp;seid=13126380643235482353&quot;</a>. CodeSheep gave a great and detailed introduction to the Hexo blog framework. As I succeed, I decided to write it down which may make your creation easier and faster.</p><p>I used MacOs, so if you encounter any difficulies, google it.</p><p>This article is served as a record for myself. All the credits should be given to CodeSheep. (<a href="https://www.codesheep.cn/" target="_blank" rel="noopener">https://www.codesheep.cn/</a>)</p><h2 id="Step-1-Download-Dependencies"><a href="#Step-1-Download-Dependencies" class="headerlink" title="Step 1: Download Dependencies"></a>Step 1: Download Dependencies</h2><p>nodejs: <a href="https://nodejs.org/en/" target="_blank" rel="noopener">https://nodejs.org/en/</a><br>git: <a href="https://git-scm.com/downloads" target="_blank" rel="noopener">https://git-scm.com/downloads</a></p><p>Open Terminal and switch to root user</p><pre><code>sudo su</code></pre><p>put your password in.</p><p>Use</p><pre><code>node -vnpm -vgit -v</code></pre><p>to confirm you successfully download node.js and Git.</p><h2 id="Addition-Step"><a href="#Addition-Step" class="headerlink" title="Addition Step"></a>Addition Step</h2><p>If you are in China, ‘cnpm’ should be faster than ‘npm’.</p><p>Install cnpm and registry to TaoBao.</p><pre><code>npm install -g cnpm --registry=https://registry.npm.taobao.org</code></pre><p>Then, in the following context, replace ‘npm’ with ‘cnpm’</p><hr><h2 id="Step-2-Download-Hexo-Framework"><a href="#Step-2-Download-Hexo-Framework" class="headerlink" title="Step 2: Download Hexo Framework"></a>Step 2: Download Hexo Framework</h2><pre><code>npm install -g hexo-cli</code></pre><p>After dowaload, you can use</p><pre><code>hexo -v</code></pre><p>to confirm.</p><hr><h2 id="Step-3-Create-a-blog"><a href="#Step-3-Create-a-blog" class="headerlink" title="Step 3: Create a blog"></a>Step 3: Create a blog</h2><p>Use</p><pre><code>mkdir blog</code></pre><p>to create a directory for you to write your blog.</p><p>In that directory, use</p><pre><code>sudo hexo init</code></pre><p>to create the blog.</p><p>Congratulations! Your blog has been created. Then you can use</p><pre><code>hexo s</code></pre><p>to start running the hexo server. By default, you should be able to access your blog locally with “<a href="http://localhost:4000/&quot;" target="_blank" rel="noopener">http://localhost:4000/&quot;</a></p><p>Basic hexo instructions can be found in your blog when you first create it. Here are some.</p><pre><code>hexo n &quot;PUT THE NAME OF YOUR POST HERE&quot;  # to creat a new posthexo clean  # to clean the bloghexo g  # to generate the blog with your posthexo s  # to run your blog locallyhexo d  # to deploy your blog</code></pre><p>The blog posts will be in MarkDown format.</p><hr><h2 id="Step-4-Deploy-your-Blog"><a href="#Step-4-Deploy-your-Blog" class="headerlink" title="Step 4: Deploy your Blog"></a>Step 4: Deploy your Blog</h2><p>To run your blog remotely, you have to deploy your blog. Here, we will deploy it on your github.</p><p>Create a new repository on Github. The Repository name has to be “YourID.github.io”!!</p><p>Use</p><pre><code>npm install --save hexo-deployer-git</code></pre><p>to download a plugin needed.</p><p>After download, modify “_config.yml” file, “Deployment” section to</p><pre><code>deploy:  type: git  repo: https://github.com/YourID/YourID.github.io.git  branch: master  # set the default branch.</code></pre><p>The ‘branch’ is not necessary unless you want to use an alternative branch of your git project.</p><p>Use the instuction</p><pre><code>hexo d</code></pre><p>to deploy the blog.</p><p>It may ask you to fill in your github ID and password. Then use “<a href="https://YourID.github.io&quot;" target="_blank" rel="noopener">https://YourID.github.io&quot;</a>, you should be able to access your blog remotely.</p><hr><h2 id="Step-5-Change-the-Theme"><a href="#Step-5-Change-the-Theme" class="headerlink" title="Step 5: Change the Theme"></a>Step 5: Change the Theme</h2><p>First, you can find a hexo theme that you like, just google it.</p><p>Here I will use mine as an example. I used hexo-theme-fluid. More details are in the github “<a href="https://github.com/fluid-dev/hexo-theme-fluid&quot;" target="_blank" rel="noopener">https://github.com/fluid-dev/hexo-theme-fluid&quot;</a>.</p><p>To use the theme, you should first download it or simply use</p><pre><code>&quot;&quot;&quot;Change the link to your selected one, and the &#39;fluid&#39; to the name you like.Better to use the theme name&quot;&quot;&quot;git clone https://github.com/fluid-dev/hexo-theme-fluid themes/fluid</code></pre><p>modify “_config.yml”, “Extensions” section. Change the theme name to your file name. In my case, it was</p><pre><code>theme: fluid</code></pre><p>Clean, generate and deploy it again. Then, the blog becomes the way you see now.</p><p>That is all. I am glad if you also manage to create one. Later, I will put more stuff on this website. May be my studies, my interests or even diaries. Hopefully, they will be helpful for you.</p><p><em>Thank you! Wish you a great day!</em></p>]]></content>
    
    
    
    <tags>
      
      <tag>Computer</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
