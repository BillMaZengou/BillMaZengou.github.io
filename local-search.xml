<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Computer Vision Foundation -&gt; Image Processing1: Digital Image Interpolation</title>
    <link href="/2020/04/19/Computer-Vision-Fundation-Image-Processing1-Digital-Image-Interpolation/"/>
    <url>/2020/04/19/Computer-Vision-Fundation-Image-Processing1-Digital-Image-Interpolation/</url>
    
    <content type="html"><![CDATA[<p>To fully understand computer vision, learning image processing is inevitable. One basic operation is to resize the images. When enlarging a small image, the resulted image may have jagged pixel edges. Image interpolation is to add a few pixels and manipulate their value in purpose so that the resulted image looks smoother.</p><p>This post is split into four sections:</p><ol><li>Two Basic Image Interpolation Algorithm</li><li>Practice with OpenCV in Python</li><li>Build <em>Resize</em> Function From Scratch</li><li>(Option) Other Interpolation Algorithm</li></ol><hr><h1 id="Two-Basic-Image-Interpolation-Algorithm"><a href="#Two-Basic-Image-Interpolation-Algorithm" class="headerlink" title="Two Basic Image Interpolation Algorithm"></a>Two Basic Image Interpolation Algorithm</h1><h3 id="Nearest-neighbour-interpolation"><a href="#Nearest-neighbour-interpolation" class="headerlink" title="Nearest-neighbour interpolation"></a>Nearest-neighbour interpolation</h3><p>When the image size increases, the extra pixels will use the same value as their nearest neighbour.<br><img src="/images/Nearest1.png" srcset="/img/loading.gif" alt="Nearest"><br>This is the simplest method. However, it is not hard to realise that this approach is problematic as it preserves the same resolution as the small image.</p><h3 id="Bilinear-interpolation"><a href="#Bilinear-interpolation" class="headerlink" title="Bilinear interpolation"></a>Bilinear interpolation</h3><p>Bilinear interpolation tries to estimate the new pixel values using information from their neighbours. Normally, linear relations are assumed in both \(x\) and \(y\) directions, namely bilinear relation. Hopefully, it will give a smoother enlarged image than <strong>Nearest-neighbour interpolation</strong>.</p><p>Typical derivation follows the logic that the enlargement should have bilinear relation and it should work to give a smoother image. Here, I decided to follow the opposite route. By assuming the resulted image is continuous and smooth, we can obtain the <strong>Bilinear interpolation</strong> without assuming bilinear relation at the first place. The full derivation will be shown in <em>Appendix</em>. Two routes are essentially equivalent.<br><img src="/images/Bilinear.png" srcset="/img/loading.gif" alt="Bilinear"><br>The equation is<br>\[<br>  \begin{equation}<br>  f(x, y) = \frac{(x_2 - x)(y_2-y)}{(x_2 - x_1)(y_2-y_1)}f(Q_{11}) + \frac{(x - x_1)(y_2-y)}{(x_2 - x_1)(y_2-y_1)}f(Q_{21}) + \frac{(x_2 - x)(y-y_1)}{(x_2 - x_1)(y_2-y_1)}f(Q_{12}) + \frac{(x - x_1)(y-y_1)}{(x_2 - x_1)(y_2-y_1)}f(Q_{22}).<br>  \end{equation}<br>\]<br>Or in matrix form,<br>\[<br>  \begin{equation}<br>  f(x, y) = \frac{1}{(x_2 - x_1)(y_2-y_1)} \begin{bmatrix} (x_2-x) &amp; (x-x_1) \end{bmatrix} \begin{bmatrix} f(Q_{11}) &amp; f(Q_{12}) \ f(Q_{21}) &amp; f(Q_{22}) \end{bmatrix} \begin{bmatrix} (y_2-y) \ (y-y_1) \end{bmatrix}.<br>  \end{equation}<br>\]</p><hr><h1 id="Practice-with-OpenCV-in-Python"><a href="#Practice-with-OpenCV-in-Python" class="headerlink" title="Practice with OpenCV in Python"></a>Practice with OpenCV in Python</h1><h3 id="Documentation"><a href="#Documentation" class="headerlink" title="Documentation"></a>Documentation</h3><p>Despite the maths looks complicated, the implementation is straightforward using OpenCV and Python.</p><pre><code>dst = cv2.resize(src, dsize[, dst[, fx[, fy[, interpolation]]]])</code></pre><p><strong>src</strong> -&gt; (compulsory) Source image.<br><strong>dst</strong> -&gt; Destination image.<br><strong>dsize</strong> -&gt; (compulsory) Destination image size. If it is \(0\), it is computed as:</p><pre><code>  dsize = Size(round(fx*src.cols), round(fy*src.rows))</code></pre><p><strong>fx</strong> -&gt; (optional) Scale factor along the horizontal axis. When it is \(0\), it is computed as:</p><pre><code>  (double)dsize.width/src.cols</code></pre><p><strong>fy</strong> -&gt; (optional) Scale factor along the vertical axis. When it is \(0\), it is computed as:</p><pre><code>  (double)dsize.height/src.rows</code></pre><p><strong>interpolation</strong> -&gt; (optional) Interpolation method:<br>  <strong>INTER_NEAREST</strong> - a nearest-neighbour interpolation<br>  <strong>INTER_LINEAR</strong> - a bilinear interpolation (used by <em>default</em>)<br>  <em>-Addition-</em><br>  <strong>INTER_AREA</strong> - resampling using pixel area relation. It may be a preferred method for image decimation, as it gives moire’-free results. But when the image is zoomed, it is similar to the <strong>INTER_NEAREST</strong> method.<br>  <strong>INTER_CUBIC</strong> - a bicubic interpolation over 4x4 pixel neighbourhood<br>  <strong>INTER_LANCZOS4</strong> - a Lanczos interpolation over 8x8 pixel neighbourhood</p><p><em>Note</em> that, normally, <strong>INTER_AREA</strong> is used when scaling down the image. Otherwise, <strong>INTER_CUBIC</strong> and <strong>INTER_LINEAR</strong> are good choices. But <strong>INTER_CUBIC</strong> is a bit slow.</p><h3 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h3><pre><code>import cv2img = cv2.imread(image_name, cv2.IMREAD_UNCHANGED)scale_percent = 5       # percent of original sizewidth = int(img.shape[1] * scale_percent / 100)height = int(img.shape[0] * scale_percent / 100)dim = (width, height)# scale down the imageresized = cv2.resize(img, dim, interpolation = cv2.INTER_LINEAR)fx = 3fy = 3# scale up the resized imageresized1 = cv2.resize(resized, dsize=None, fx=fx, fy=fy, interpolation = cv2.INTER_NEAREST)resized2 = cv2.resize(resized, dsize=None, fx=fx, fy=fy, interpolation = cv2.INTER_LINEAR)# display the resultscv2.imshow(&quot;Resized image&quot;, resized)cv2.imshow(&quot;INTER_NEAREST image&quot;, resized1)cv2.imshow(&quot;INTER_LINEAR image&quot;, resized2)# Press &#39;s&#39; for saving the imagek = cv2.waitKey(0)if k == 27:         # wait for ESC key to exit    cv2.destroyAllWindows()elif k == ord(&#39;s&#39;): # wait for &#39;s&#39; key to save and exit    cv2.imwrite(&quot;Resized_image.jpg&quot;,resized)    cv2.imwrite(&quot;INTER_NEAREST_image.jpg&quot;,resized1)    cv2.imwrite(&quot;INTER_LINEAR_image.jpg&quot;,resized2)    cv2.destroyAllWindows()</code></pre><p>Example results are shown below:<br><strong>Scale down the original image by 95% using Bilinear interpolation</strong><br><img src="/images/Resized_image.jpg" srcset="/img/loading.gif" alt="small"></p><p><strong>Scale up the resized image by 30% using Nearest-neighbour interpolation</strong><br><img src="/images/INTER_NEAREST_image.jpg" srcset="/img/loading.gif" alt="nearest_image"></p><p><strong>Scale up the resized image by 30% using Bilinear interpolation</strong><br><img src="/images/INTER_LINEAR_image.jpg" srcset="/img/loading.gif" alt="bilinear_image"><br>It is clear that the result of the Bilinear interpolation is much smoother than it of the Nearest-neighbour interpolation.</p><hr><h2 id="Build-Resize-Function-From-Scratch-TODO"><a href="#Build-Resize-Function-From-Scratch-TODO" class="headerlink" title="Build Resize Function From Scratch (TODO)"></a>Build <em>Resize</em> Function From Scratch (TODO)</h2><hr><h2 id="Option-Other-Interpolation-Algorithm-TODO"><a href="#Option-Other-Interpolation-Algorithm-TODO" class="headerlink" title="(Option) Other Interpolation Algorithm (TODO)"></a>(Option) Other Interpolation Algorithm (TODO)</h2><hr><h2 id="Appendix-Derivation-of-Bilinear-interpolation"><a href="#Appendix-Derivation-of-Bilinear-interpolation" class="headerlink" title="Appendix - Derivation of Bilinear interpolation"></a>Appendix - Derivation of Bilinear interpolation</h2><p><img src="/images/Bilinear.png" srcset="/img/loading.gif" alt="Bilinear"><br>Assumptions: The image is smooth in any directions; \(Q_{11}\), \(Q_{12}\), \(Q_{21}\), \(Q_{22}\), \(R_1\), \(R_2\) and \(P\) are close enough.</p><p>Follow by the assumptions, we have<br>\[<br>\begin{equation}<br>f(R_1) = f(P) - \frac{\partial f(P)}{\partial y}\bigg|<em>{x} (y-y_1);<br>f(R_2) = f(P) + \frac{\partial f(P)}{\partial y}\bigg|</em>{x} (y_2-y).<br>\end{equation}<br>\]<br>Then,<br>\[<br>\begin{equation}<br>f(Q_{11}) = f(R_1) - \frac{\partial f(R_1)}{\partial x}\bigg|<em>{y1} (x-x_1); f(Q</em>{21}) = f(R_1) + \frac{\partial f(R_1)}{\partial x}\bigg|<em>{y1} (x_2-x);<br>\end{equation}<br>\begin{equation}<br>f(Q</em>{12}) = f(R_2) - \frac{\partial f(R_2)}{\partial x}\bigg|<em>{y2} (x-x_1); f(Q</em>{22}) = f(R_2) + \frac{\partial f(R_2)}{\partial x}\bigg|<em>{y2} (x_2-x).<br>\end{equation}<br>\]<br>Substituting \(f(R_1)\) and \(f(R_2)\) into the equations, we find that<br>$$<br>\begin{equation}<br>f(Q</em>{11}) = f(P) - \frac{\partial f(P)}{\partial y}\bigg|<em>{x} (y-y_1) - \frac{\partial f(P)}{\partial x}\bigg|</em>{y_1} (x-x_1) + \frac{\partial^2 f(P)}{\partial x \partial y}\bigg|<em>{y_1} (x-x_1) (y-y_1),<br>\end{equation}<br>$$<br>the last term equals \(0\) as the function is evaluated at \(y=y_1\). Therefore, we have<br>$$<br>\begin{equation}<br>f(Q</em>{11}) = f(P) - \frac{\partial f(P)}{\partial y}\bigg|<em>{x} (y-y_1) - \frac{\partial f(P)}{\partial x}\bigg|</em>{y_1} (x-x_1);<br>\end{equation}<br>\begin{equation}<br>f(Q_{21}) = f(P) - \frac{\partial f(P)}{\partial y}\bigg|<em>{x} (y-y_1) + \frac{\partial f(P)}{\partial x}\bigg|</em>{y_1} (x_2-x);<br>\end{equation}<br>\begin{equation}<br>f(Q_{12}) = f(P) + \frac{\partial f(P)}{\partial y}\bigg|<em>{x} (y_2-y) - \frac{\partial f(P)}{\partial x}\bigg|</em>{y_2} (x-x_1);<br>\end{equation}<br>\begin{equation}<br>f(Q_{22}) = f(P) + \frac{\partial f(P)}{\partial y}\bigg|<em>{x} (y_2-y) + \frac{\partial f(P)}{\partial x}\bigg|</em>{y_2} (x_2-x).<br>\end{equation}<br>$$</p><p>By rearranging the equations, we can find that<br>$$<br>\begin{equation}<br>\frac{\partial f(P)}{\partial y}\bigg|<em>{x} (y-y_1) = f(P) - f(Q</em>{11}) - \frac{\partial f(P)}{\partial x}\bigg|<em>{y_1} (x-x_1) = f(P) - f(Q</em>{21}) + \frac{\partial f(P)}{\partial x}\bigg|<em>{y_1} (x_2-x);<br>\end{equation}<br>\begin{equation}<br>\frac{\partial f(P)}{\partial y}\bigg|</em>{x} (y_2-y) = f(Q_{12}) - f(P) +  \frac{\partial f(P)}{\partial x}\bigg|<em>{y_2} (x-x_1) = f(Q</em>{22}) - f(P) - \frac{\partial f(P)}{\partial x}\bigg|<em>{y_2} (x_2-x).<br>\end{equation}<br>$$<br>Then,<br>$$<br>\begin{equation}<br>\frac{\partial f(P)}{\partial x}\bigg|</em>{y_1} = \frac{f(Q_{21}) - f(Q_{11})}{x_2-x_1};<br>\end{equation}<br>\begin{equation}<br>\frac{\partial f(P)}{\partial x}\bigg|<em>{y_2} = \frac{f(Q</em>{22}) - f(Q_{12})}{x_2-x_1}.<br>\end{equation}<br>$$</p><p>Substituting the above equations back, we can fine \(\frac{\partial f(x, y)}{\partial y}\bigg|<em>{x}\) as<br>$$<br>\begin{equation}<br>\frac{\partial f(x, y)}{\partial y}\bigg|</em>{x} = \frac{f(P) - f(Q_{11})}{y-y_1} - \frac{x-x_1}{y-y_1}\frac{f(Q_{21} - f(Q_{11}))}{x_2-x_1} = \frac{f(Q_{12} - f(P))}{y_2-y} - \frac{x-x_1}{y_2-y}\frac{f(Q_{22} - f(Q_{12}))}{x_2-x_1}.<br>\end{equation}<br>$$</p><p>Rearrange to get \(f(x, y)\). Finally, we have the <strong>Bilinear relation</strong> that we want.<br>$$<br>\begin{equation}<br>f(x, y) = \frac{(x_2 - x)(y_2-y)}{(x_2 - x_1)(y_2-y_1)}f(Q_{11}) + \frac{(x - x_1)(y_2-y)}{(x_2 - x_1)(y_2-y_1)}f(Q_{21}) + \frac{(x_2 - x)(y-y_1)}{(x_2 - x_1)(y_2-y_1)}f(Q_{12}) + \frac{(x - x_1)(y-y_1)}{(x_2 - x_1)(y_2-y_1)}f(Q_{22}).<br>\end{equation}<br>$$</p><hr><h2 id="Acknowledgement"><a href="#Acknowledgement" class="headerlink" title="Acknowledgement"></a>Acknowledgement</h2><p>The creation of this post is inspired by <strong>Datawhale</strong>.</p><hr><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li>Blog.csdn.net. 2020. Opencv框架与图像插值算法_网络_Weixin_39940512的博客-CSDN博客. [online] Available at: <a href="https://blog.csdn.net/weixin_39940512/article/details/105343418" target="_blank" rel="noopener">https://blog.csdn.net/weixin_39940512/article/details/105343418</a> [Accessed 20 April 2020].</li><li>Angel, A., 2020. Nearest Neighbor Interpolation. [online] Imageeprocessing.com. Available at: <a href="https://www.imageeprocessing.com/2017/11/nearest-neighbor-interpolation.html" target="_blank" rel="noopener">https://www.imageeprocessing.com/2017/11/nearest-neighbor-interpolation.html</a> [Accessed 19 April 2020].</li><li>En.wikipedia.org. 2020. Bilinear Interpolation. [online] Available at: <a href="https://en.wikipedia.org/wiki/Bilinear_interpolation" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Bilinear_interpolation</a> [Accessed 20 April 2020].</li><li>Opencv.org.cn. 2020. Geometric Image Transformations — Opencv 2.3.2 Documentation. [online] Available at: <a href="http://www.opencv.org.cn/opencvdoc/2.3.2/html/modules/imgproc/doc/geometric_transformations.html?highlight=resize#cv.Resize" target="_blank" rel="noopener">http://www.opencv.org.cn/opencvdoc/2.3.2/html/modules/imgproc/doc/geometric_transformations.html?highlight=resize#cv.Resize</a> [Accessed 20 April 2020].</li><li>Photo by Viktor Mogilat on Unsplash.</li><li>Opencv-python-tutroals.readthedocs.io. 2020. Getting Started With Images — Opencv-Python Tutorials 1 Documentation. [online] Available at: <a href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_image_display/py_image_display.html" target="_blank" rel="noopener">https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_image_display/py_image_display.html</a> [Accessed 20 April 2020].</li></ol><hr>]]></content>
    
    
    
    <tags>
      
      <tag>Computer</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Quarantine-Day-2|隔离第二天</title>
    <link href="/2020/04/16/Quarantine-Day-2-%E9%9A%94%E7%A6%BB%E7%AC%AC%E4%BA%8C%E5%A4%A9/"/>
    <url>/2020/04/16/Quarantine-Day-2-%E9%9A%94%E7%A6%BB%E7%AC%AC%E4%BA%8C%E5%A4%A9/</url>
    
    <content type="html"><![CDATA[<p>Today is the second day of my quarantine session. Due to the unespected situation and my original career path, I decided to accelerate my job hunting. But when I begin, I am a little comfused and upset. I understand I need sometime to digest a new way of thinking. I might be immature and naive. I almost spent the whole day in looking for information and filling up different files. </p><p>To summarise some points that I obtained today, I need to firm my essential coding skills. I did not learn programming until last year, but it cannot be my excuse. Also, I need to find out how I can use what I know to make profit. This year, I learned about Computer Vision, Graphics, VR/AR. I enjoyed learning new stuff but worried little about what I can do with these cutting-edge technologies. Also, I need to link these back to the fundamental data sturctures and popular libraries. </p><p>Hope today’s work can help me make my mind!</p>]]></content>
    
    
    
    <tags>
      
      <tag>Diary</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Weight Record</title>
    <link href="/2020/04/15/Weight-Record/"/>
    <url>/2020/04/15/Weight-Record/</url>
    
    <content type="html"><![CDATA[<p><em>Goal</em>: 70kg</p><p>One-punch Man Training:</p><ol><li>Push-ups - 100 times</li><li>Sit-ups - 100 times</li><li>Squats - 100 times</li><li>Jogging - 10km</li></ol><hr><h1 id="Date-2020-04-15"><a href="#Date-2020-04-15" class="headerlink" title="Date: 2020/04/15"></a>Date: 2020/04/15</h1><p>Weight: 77kg<br>Activity: N/A</p><h1 id="Date-2020-04-16"><a href="#Date-2020-04-16" class="headerlink" title="Date: 2020/04/16"></a>Date: 2020/04/16</h1><p>Weight: 77kg<br>Activity: 50% of 1 - 3 </p><h1 id="Date-2020-04-17"><a href="#Date-2020-04-17" class="headerlink" title="Date: 2020/04/17"></a>Date: 2020/04/17</h1><p>Weight: 77kg<br>Activity: 50% of 1 - 3    </p>]]></content>
    
    
    
    <tags>
      
      <tag>Diary</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Quarantine Day 1|隔离第一天</title>
    <link href="/2020/04/15/Quarantine-Day-1-%E9%9A%94%E7%A6%BB%E7%AC%AC%E4%B8%80%E5%A4%A9/"/>
    <url>/2020/04/15/Quarantine-Day-1-%E9%9A%94%E7%A6%BB%E7%AC%AC%E4%B8%80%E5%A4%A9/</url>
    
    <content type="html"><![CDATA[<p>Today is 2020/04/15. I have arrived in Shanghai and begun my quarantine life. As I have two upcoming deadlines, I will dedicate my time on two topics during the quarantine period. One is <strong>volumetric transform</strong>, the other is <strong>using asymmetric vibration to induce sensation of force</strong>. Because of UCL school policy, I am not allowed to show my coursework in detail. I will only show briefly the literature review and my understandings of the second topics. Later, I will probably show you the results of the first topics. Also, I will make a series of topics in <strong>Computer Vision</strong> when I do my revision during and after the quarantine period.</p><p>One thing I found intriguing in the area of VR was haptics. Nowadays, there are many ways to use human hands to interact with virtual objects. They are easier and more intuitive than the normal VR controllers. The cheapest way is the hand tracking using cameras. For example, Oculus has announced that they will include hand tracking in the latest Oculus Quest; Leap Motion has worked in this field for a decade. Despite, using visual information is cheap, it is not always reliable as the hand position, orientation, light and occlusion conditions are constantly varying. Haptics glove is one alternative. Data-driven gloves can precisely track our hand and fingers. Plus, with the available data, force feedback haptics can be built.</p><p>Personally, I believed that force feedback haptic glove is the future of VR interaction. Users cannot only touch, hold and move virtual objects, but also feel the shape, reaction force, texture or even temperature of the virtual objects. Is not a fascinating idea?</p>]]></content>
    
    
    
    <tags>
      
      <tag>Diary, Computer</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Create A Blog|创建博客</title>
    <link href="/2020/04/13/Create-A-Blog-%E5%88%9B%E5%BB%BA%E5%8D%9A%E5%AE%A2/"/>
    <url>/2020/04/13/Create-A-Blog-%E5%88%9B%E5%BB%BA%E5%8D%9A%E5%AE%A2/</url>
    
    <content type="html"><![CDATA[<p>Today is 2020/04/13, I will be on the plane to China in about 10 hours. I heard about how writing blog would help improve IT skills for a long time, but did not know when and how to start. Now I finally made my mind to create a blog. For thhe processes, I conducted “<a href="https://www.bilibili.com/video/BV1Yb411a7ty?from=search&amp;seid=13126380643235482353&quot;" target="_blank" rel="noopener">https://www.bilibili.com/video/BV1Yb411a7ty?from=search&amp;seid=13126380643235482353&quot;</a>. CodeSheep gave a great and detailed introduction to the Hexo blog framework. As I succeed, I decided to write it down which may make your creation easier and faster.</p><p>I used MacOs, so if you encounter any difficulies, google it.</p><p>This article is served as a record for myself. All the credits should be given to CodeSheep. (<a href="https://www.codesheep.cn/" target="_blank" rel="noopener">https://www.codesheep.cn/</a>)</p><h2 id="Step-1-Download-Dependencies"><a href="#Step-1-Download-Dependencies" class="headerlink" title="Step 1: Download Dependencies"></a>Step 1: Download Dependencies</h2><p>nodejs: <a href="https://nodejs.org/en/" target="_blank" rel="noopener">https://nodejs.org/en/</a><br>git: <a href="https://git-scm.com/downloads" target="_blank" rel="noopener">https://git-scm.com/downloads</a></p><p>Open Terminal and switch to root user</p><pre><code>sudo su</code></pre><p>put your password in.</p><p>Use</p><pre><code>node -vnpm -vgit -v</code></pre><p>to confirm you successfully download node.js and Git.</p><h2 id="Addition-Step"><a href="#Addition-Step" class="headerlink" title="Addition Step"></a>Addition Step</h2><p>If you are in China, ‘cnpm’ should be faster than ‘npm’.</p><p>Install cnpm and registry to TaoBao.</p><pre><code>npm install -g cnpm --registry=https://registry.npm.taobao.org</code></pre><p>Then, in the following context, replace ‘npm’ with ‘cnpm’</p><hr><h2 id="Step-2-Download-Hexo-Framework"><a href="#Step-2-Download-Hexo-Framework" class="headerlink" title="Step 2: Download Hexo Framework"></a>Step 2: Download Hexo Framework</h2><pre><code>npm install -g hexo-cli</code></pre><p>After dowaload, you can use</p><pre><code>hexo -v</code></pre><p>to confirm.</p><hr><h2 id="Step-3-Create-a-blog"><a href="#Step-3-Create-a-blog" class="headerlink" title="Step 3: Create a blog"></a>Step 3: Create a blog</h2><p>Use</p><pre><code>mkdir blog</code></pre><p>to create a directory for you to write your blog.</p><p>In that directory, use</p><pre><code>sudo hexo init</code></pre><p>to create the blog.</p><p>Congratulations! Your blog has been created. Then you can use</p><pre><code>hexo s</code></pre><p>to start running the hexo server. By default, you should be able to access your blog locally with “<a href="http://localhost:4000/&quot;" target="_blank" rel="noopener">http://localhost:4000/&quot;</a></p><p>Basic hexo instructions can be found in your blog when you first create it. Here are some.</p><pre><code>hexo n &quot;PUT THE NAME OF YOUR POST HERE&quot;  # to creat a new posthexo clean  # to clean the bloghexo g  # to generate the blog with your posthexo s  # to run your blog locallyhexo d  # to deploy your blog</code></pre><p>The blog posts will be in MarkDown format.</p><hr><h2 id="Step-4-Deploy-your-Blog"><a href="#Step-4-Deploy-your-Blog" class="headerlink" title="Step 4: Deploy your Blog"></a>Step 4: Deploy your Blog</h2><p>To run your blog remotely, you have to deploy your blog. Here, we will deploy it on your github.</p><p>Create a new repository on Github. The Repository name has to be “YourID.github.io”!!</p><p>Use</p><pre><code>npm install --save hexo-deployer-git</code></pre><p>to download a plugin needed.</p><p>After download, modify “_config.yml” file, “Deployment” section to</p><pre><code>deploy:  type: git  repo: https://github.com/YourID/YourID.github.io.git  branch: master  # set the default branch.</code></pre><p>The ‘branch’ is not necessary unless you want to use an alternative branch of your git project.</p><p>Use the instuction</p><pre><code>hexo d</code></pre><p>to deploy the blog.</p><p>It may ask you to fill in your github ID and password. Then use “<a href="https://YourID.github.io&quot;" target="_blank" rel="noopener">https://YourID.github.io&quot;</a>, you should be able to access your blog remotely.</p><hr><h2 id="Step-5-Change-the-Theme"><a href="#Step-5-Change-the-Theme" class="headerlink" title="Step 5: Change the Theme"></a>Step 5: Change the Theme</h2><p>First, you can find a hexo theme that you like, just google it.</p><p>Here I will use mine as an example. I used hexo-theme-fluid. More details are in the github “<a href="https://github.com/fluid-dev/hexo-theme-fluid&quot;" target="_blank" rel="noopener">https://github.com/fluid-dev/hexo-theme-fluid&quot;</a>.</p><p>To use the theme, you should first download it or simply use</p><pre><code>&quot;&quot;&quot;Change the link to your selected one, and the &#39;fluid&#39; to the name you like.Better to use the theme name&quot;&quot;&quot;git clone https://github.com/fluid-dev/hexo-theme-fluid themes/fluid</code></pre><p>modify “_config.yml”, “Extensions” section. Change the theme name to your file name. In my case, it was</p><pre><code>theme: fluid</code></pre><p>Clean, generate and deploy it again. Then, the blog becomes the way you see now.</p><p>That is all. I am glad if you also manage to create one. Later, I will put more stuff on this website. May be my studies, my interests or even diaries. Hopefully, they will be helpful for you.</p><p><em>Thank you! Wish you a great day!</em></p>]]></content>
    
    
    
    <tags>
      
      <tag>Computer</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
