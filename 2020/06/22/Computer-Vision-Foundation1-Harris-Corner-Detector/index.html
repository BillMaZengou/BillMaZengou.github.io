<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="UCL MRes Virtual Reality; University of Warwick BSc Physics">
  <meta name="author" content="Zengou Ma">
  <meta name="keywords" content="">
  <title>Computer Vision Foundation 1: Harris Corner Detector - Bill Ma&#39;s Blog</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/3.0.1/github-markdown.min.css" />

<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_9n5xqdrq0nc.css">



  <link  rel="stylesheet" href="/lib/prettify/tomorrow-night-eighties.min.css" />




<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


<meta name="generator" content="Hexo 4.2.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>


<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Bill Ma's Blog</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">
              <i class="iconfont icon-home-fill"></i>
              首页</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">
              <i class="iconfont icon-archive-fill"></i>
              归档</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">
              <i class="iconfont icon-category-fill"></i>
              分类</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">
              <i class="iconfont icon-tags-fill"></i>
              标签</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">
              <i class="iconfont icon-user-fill"></i>
              关于</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
                <div class="mt-3 post-meta">
                  <i class="iconfont icon-date-fill" aria-hidden="true"></i>
                  <time datetime="2020-06-22 20:18">
                    星期一, 六月 22日 2020, 8:18 晚上
                  </time>
                </div>
              

              <div class="mt-1">
                
                  
                  <span class="post-meta mr-2">
                    <i class="iconfont icon-chart"></i>
                    1.3k 字
                  </span>
                

                
                  
                  <span class="post-meta mr-2">
                      <i class="iconfont icon-clock-fill"></i>
                    
                    
                    25
                     分钟
                  </span>
                

                
              </div>
            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
            <article class="markdown-body">
              <p>In this series of posts, with the foundation of image processing, we will look at some key ideas in Computer Vision. One important progress in CV is the corner detector. Recall from  <strong>Computer Vision Foundation -&gt; Image Processing6: Edge Detection</strong>, previously we were able to find edges. However, interest-point detector is more critical. The interest-point can be used as an indicator to find the same object or position in two different images.</p>
<p>This post is split into four sections:</p>
<ol>
<li>The Basic Principles of Harris Corner Detector</li>
<li>Practice with OpenCV in Python</li>
<li>Compute Harris Corner Detector From Scratch</li>
</ol>
<p>Source code: <a href="https://github.com/BillMaZengou/cv_basis" target="_blank" rel="noopener">https://github.com/BillMaZengou/cv_basis</a> -&gt; <a href="http://harris.py" target="_blank" rel="noopener">harris.py</a> (OpenCV)</p>
<hr />
<h1 id="the-basic-principles-of-harris-corner-detector"><a class="markdownIt-Anchor" href="#the-basic-principles-of-harris-corner-detector"></a> The Basic Principles of Harris Corner Detector</h1>
<p>Originally, when people wanted to do some operations across multiple images, they would do patch matching, which meant that they needed to compare a portion of the image with anywhere else and compute the similarity. As shown in the picture below, computer needs to compare each patch and calculates the correlation.<br />
<img src="patch_detection.png" srcset="/img/loading.gif" alt="patch" /></p>
<p>However, this approach is not robust. Consider the example below, it is hard to tell which section of the sky is the same as our target as the sky looks identical.<br />
<img src="bad_patch.png" srcset="/img/loading.gif" alt="bad" /></p>
<p>This should give us an insight that using patch detection through the whole image is not a reliable way to find the same position between multiple images. Moreover, only the distinct features should be considered.</p>
<p>The interest points are the local features that associated with a significant change of an image property or several properties simultaneously (e.g. intensity, colour, texture).</p>
<p><strong>Six properties of good features</strong></p>
<ol>
<li>Local: features are local, robust to occlusion and clutter. (i.e. no prior segmentation required)</li>
<li>Accurate: precise localisation.</li>
<li>Invariant (or covariant)</li>
<li>Robust: noise, blur, compression, etc. do not have a big impact on the feature.</li>
<li>Distinctive: individual features can be matched to a large database of objects.</li>
<li>Efficient: close to real-time performance.</li>
</ol>
<p>The properties 3. and 4. make the detector repeatable across multiple images.</p>
<p>Therefore, a natural selection of our interest points is the corners. Corners are locations where variations of intensity function \(f(x, y)\) in both \(x\) and \(y\) directions are high. (i.e. the partial derivatives of \(f(x, y)\) with respect to \(x\) and \(y\) are large)</p>
<p>On the contrast, for an edge, the partial derivative is large in only a certain direction; for a flat surface, the partial derivatives are small in both directions.</p>
<p>Harris corner detector uses these properties. Consider a small window (a kernel) on each pixel, and compute the partial derivatives by moving the kernel.<br />
<img src="harris.png" srcset="/img/loading.gif" alt="harris" /></p>
<p><strong>The Algorithm</strong><br />
<img src="step.png" srcset="/img/loading.gif" alt="steps" /></p>
<ol>
<li>For each pixel in the input image, the corner operator is applied to obtain a <em>cornerness</em> measure for this pixel.</li>
<li><em>Threshold cornerness map</em> to eliminate weak corners.</li>
<li>Apply <em>non-maximal suppression</em> to eliminate points whose cornerness measure is not larger than the cornerness values of all points within a certain distance.</li>
</ol>
<p>Mathematically, the change of intensity for the shift \([u, v]\) can be expressed as<br />
\[<br />
E(u, v) = \sum_{x, y} w(x, y) [I(x+u, y+v) - I(x, y)]^2<br />
\]<br />
where \(w(x, y)\) is the window function and \(I(x, y)\) is the intensity function. The element in the window function can all be \(1\) or Gaussian distributed.</p>
<p>To simplify the equation and ease our computational costs, we can use first-order Taylor expansion on the square term.<br />
\[<br />
I(x+u, y+v) \approx I(x, y) +<br />
\begin{bmatrix}<br />
\frac{\partial I}{\partial x} &amp; \frac{\partial I}{\partial y}<br />
\end{bmatrix}<br />
\begin{bmatrix}<br />
u\\<br />
v<br />
\end{bmatrix}<br />
\]<br />
Thus, the square term can be considered as<br />
\[<br />
(\begin{bmatrix}<br />
\frac{\partial I}{\partial x} &amp; \frac{\partial I}{\partial y}<br />
\end{bmatrix}<br />
\begin{bmatrix}<br />
u\\<br />
v<br />
\end{bmatrix})^2<br />
\]<br />
using a matrix identity: \(\mathbf{u}^2 = \mathbf{u}^{T}\mathbf{u}\), it becomes<br />
\[<br />
\begin{bmatrix}<br />
u &amp; v<br />
\end{bmatrix}<br />
\begin{bmatrix}<br />
\frac{\partial I}{\partial x} \\ \frac{\partial I}{\partial y}<br />
\end{bmatrix}<br />
\begin{bmatrix}<br />
\frac{\partial I}{\partial x} &amp; \frac{\partial I}{\partial y}<br />
\end{bmatrix}<br />
\begin{bmatrix}<br />
u\\<br />
v<br />
\end{bmatrix}<br />
\]<br />
Therefore,<br />
\[<br />
E(u, v) \approx<br />
\begin{bmatrix}<br />
u &amp; v<br />
\end{bmatrix}<br />
\mathbf{M}<br />
\begin{bmatrix}<br />
u\\<br />
v<br />
\end{bmatrix}<br />
\]<br />
where<br />
\[<br />
\mathbf{M} = \sum_{x, y} w(x, y)<br />
\begin{bmatrix}<br />
\frac{\partial^2 I}{\partial x^2} &amp; \frac{\partial^2 I}{\partial x \partial y} \\<br />
\frac{\partial^2 I}{\partial x \partial y} &amp; \frac{\partial^2 I}{\partial y^2}<br />
\end{bmatrix}<br />
\]</p>
<p>Diagonalising the matrix \(\mathbf{M}\) gives us<br />
\[<br />
\mathbf{M} = \mathbf{P}^{-1}<br />
\begin{bmatrix}<br />
\lambda_1 &amp; 0 \\<br />
0 &amp; \lambda_2<br />
\end{bmatrix}<br />
\mathbf{P}<br />
\]<br />
where \(\lambda_1\) and \(\lambda_2\) are the eigenvalues of \(\mathbf{M}\)</p>
<p>Then \(\lambda_1\) and \(\lambda_2\) can be used to compute a score, \(R\) such that<br />
\[<br />
R = det(\mathbf{M}) - k(trace(\mathbf{M}))^2 = \lambda_1 \lambda_2 - k (\lambda_1+\lambda_2)^2<br />
\]<br />
where \(k\) is a tunable sensitivity parameter. Empirically, it is around \(0.04-0.06\).</p>
<p>Different \(R\) values can categorise a feature into flat surfaces, edges and corners.<br />
<img src="r.png" srcset="/img/loading.gif" alt="cate" /></p>
<p>Normally, it follows this pattern.<br />
<img src="harrisClass.png" srcset="/img/loading.gif" alt="class" /></p>
<p>The properties of Harris Corner Detector were studied.<br />
<img src="properties.png" srcset="/img/loading.gif" alt="property" /><br />
It is clear that Harris is invariant under the rotation but <strong>not</strong> invariant after scaling up.</p>
<hr />
<h1 id="practice-with-opencv-in-python"><a class="markdownIt-Anchor" href="#practice-with-opencv-in-python"></a> Practice with OpenCV in Python</h1>
<h3 id="documentation"><a class="markdownIt-Anchor" href="#documentation"></a> Documentation</h3>
<p>In OpenCV, we can use <code>cv2.cornerHarris</code> to implement a Harris corner detector.</p>
<pre class="highlight"><code class="">dst = cv2.cornerHarris(src, blockSize, ksize, k, borderType=BORDER_DEFAULT)
</code></pre>
<p><strong>src</strong> -&gt; (compulsory) Input single-channel 8-bit or floating-point image.<br />
<strong>dst</strong> -&gt; Image to store the Harris detector responses.<br />
<strong>blockSize</strong> -&gt; (compulsory) Neighbourhood size.<br />
<strong>ksize</strong> -&gt; (compulsory) Aperture parameter for the Sobel operator. For more information about the Sobel operator, check <strong>Computer Vision Foundation -&gt; Image Processing6: Edge Detection</strong>.<br />
<strong>k</strong> -&gt; (compulsory) Harris detector free parameter.<br />
<strong>borderType</strong> -&gt; (optional) Pixel extrapolation method. <em>BORDER_WRAP</em> is not supported. The default option is <em>BORDER_DEFAULT</em>.</p>
<p><em>Note</em> In OpenCV, <code>borderType</code><br />
\[<br />
\begin{center}<br />
\begin{tabular}{ |c|c| }<br />
\hline<br />
<code>cv.BORDER_CONSTANT</code> &amp; <code>iiiiii|abcdefgh|iiiiiii</code> with a specific <code>i</code> \<br />
<code>cv.BORDER_REPLICATE</code> &amp; <code>aaaaaa|abcdefgh|hhhhhhh</code> \<br />
<code>cv.BORDER_REFLECT</code> &amp; <code>fedcba|abcdefgh|hgfedcb</code> \<br />
<code>cv.BORDER_WRAP</code> &amp; <code>cdefgh|abcdefgh|abcdefg</code> \<br />
<code>cv.BORDER_REFLECT_101</code> &amp; <code>gfedcb|abcdefgh|gfedcba</code> \<br />
<code>cv.BORDER_TRANSPARENT</code> &amp; <code>uvwxyz|abcdefgh|ijklmno</code> \<br />
\hline<br />
\end{tabular}<br />
\end{center}<br />
\]<br />
<code>cv.BORDER_DEFAULT</code> is as the same as <code>cv.BORDER_REFLECT_101</code>.</p>
<h3 id="implementation"><a class="markdownIt-Anchor" href="#implementation"></a> Implementation</h3>
<pre class="highlight"><code class="">import cv2

# detector parameters
block_size = 3
sobel_size = 3
k = 0.06

name = image_name
img = cv2.imread('./{}.jpg'.format(name), cv2.IMREAD_UNCHANGED)
img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
# modify the data type setting to 32-bit floating point
img = np.float32(img)

# detect the corners with appropriate values as input parameters
corners_img = cv2.cornerHarris(img, block_size, sobel_size, k)

#result is dilated for marking the corners, not important
dst = cv2.dilate(dst, None)

# Threshold for an optimal value, marking the corners in Green
image[corners_img&gt;0.01*dst.max()] = [0,255,0]

cv2.imshow('Harris Corner Detector',image)
cv2.waitKey(0)
cv2.destroyAllWindows()
</code></pre>
<p>Example results are shown below:<br />
<strong>Original image</strong><br />
<img src="train.jpg" srcset="/img/loading.gif" alt="train" /></p>
<p><strong>Interest Points</strong><br />
<img src="train_interest_points.jpg" srcset="/img/loading.gif" alt="corner" /></p>
<p><em>Note</em> More details about <code>cv2.dilate</code>, please conduct <em><a href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.html" target="_blank" rel="noopener">https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.html</a></em></p>
<hr />
<h1 id="compute-harris-corner-detector-from-scratch-todo"><a class="markdownIt-Anchor" href="#compute-harris-corner-detector-from-scratch-todo"></a> Compute Harris Corner Detector From Scratch (TODO)</h1>
<hr />
<h1 id="acknowledgement"><a class="markdownIt-Anchor" href="#acknowledgement"></a> Acknowledgement</h1>
<p>The creation of this post is inspired by <strong>Datawhale</strong>.</p>
<hr />
<h1 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h1>
<ol>
<li><a href="http://Cse.psu.edu" target="_blank" rel="noopener">Cse.psu.edu</a>. 2020. [online] Available at: <a href="http://www.cse.psu.edu/~rtc12/CSE486/lecture06.pdf" target="_blank" rel="noopener">http://www.cse.psu.edu/~rtc12/CSE486/lecture06.pdf</a> [Accessed 23 June 2020].</li>
<li>
<ol start="2020">
<li>[online] Available at: <a href="https://zhuanlan.zhihu.com/p/83064609" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/83064609</a> [Accessed 23 June 2020].</li>
</ol>
</li>
<li><a href="http://Docs.opencv.org" target="_blank" rel="noopener">Docs.opencv.org</a>. 2020. Opencv: Harris Corner Detection. [online] Available at: <a href="https://docs.opencv.org/3.4/dc/d0d/tutorial_py_features_harris.html" target="_blank" rel="noopener">https://docs.opencv.org/3.4/dc/d0d/tutorial_py_features_harris.html</a> [Accessed 23 June 2020].</li>
<li><a href="http://Opencv-python-tutroals.readthedocs.io" target="_blank" rel="noopener">Opencv-python-tutroals.readthedocs.io</a>. 2020. Harris Corner Detection — Opencv-Python Tutorials 1 Documentation. [online] Available at: <a href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_features_harris/py_features_harris.html" target="_blank" rel="noopener">https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_features_harris/py_features_harris.html</a> [Accessed 23 June 2020].</li>
<li>Schmid, C., Mohr, R. and Bauckhage, C., 2000. Evaluation of interest point detectors. International Journal of computer vision, 37(2), pp.151-172.</li>
</ol>
<hr />

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/Computer/">Computer</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://zh.wikipedia.org/wiki/Wikipedia:CC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" target="_blank" rel="nofollow noopener noopener">CC BY-SA 3.0协议</a> 。转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2020/05/18/CV-Foundation-Competition-Street-View-House-Numbers1-Data-Understanding/">
                        <span class="hidden-mobile">CV Foundation (Competition) -> Street View House Numbers1: Data Understanding</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    

    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/main.js" ></script>


  <script  src="/js/lazyload.js" ></script>



  
  <script  src="https://cdn.staticfile.org/tocbot/4.10.0/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: '.post-content',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>





  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>






<!-- Plugins -->



  <script  src="https://cdn.staticfile.org/prettify/188.0.0/prettify.min.js" ></script>
  <script>
    $(document).ready(function () {
      $('pre').each(function () {
        const pre = $(this);
        if (pre.find('code.mermaid').length > 0) {
          return;
        }
        pre.addClass('prettyprint  linenums');
      });
      prettyPrint();
    })
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "Computer Vision Foundation 1: Harris Corner Detector&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>





  

  
    <!-- MathJax -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
          tex2jax: {
              inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
              processEscapes: true,
              skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
          }
      });
      MathJax.Hub.Register.StartupHook("End Jax",function () {
        var BROWSER = MathJax.Hub.Browser;
        var jax = "HTML-CSS";
        if (BROWSER.isMSIE && BROWSER.hasMathPlayer) jax = "NativeMML";
        return MathJax.Hub.setRenderer(jax);
      });
      MathJax.Hub.Queue(function() {
          var all = MathJax.Hub.getAllJax(), i;
          for(i=0; i < all.length; i += 1) {
              all[i].SourceElement().parentNode.className += ' has-jax';
          }
      });

    </script>

    <script  src="https://cdn.staticfile.org/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML" ></script>

  














<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body>
</html>
