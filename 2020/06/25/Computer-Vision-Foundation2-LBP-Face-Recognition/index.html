<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="UCL MRes Virtual Reality; University of Warwick BSc Physics">
  <meta name="author" content="Zengou Ma">
  <meta name="keywords" content="">
  <title>Computer Vision Foundation 2: LBP Face Recognition - Bill Ma&#39;s Blog</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/3.0.1/github-markdown.min.css" />

<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_9n5xqdrq0nc.css">



  <link  rel="stylesheet" href="/lib/prettify/tomorrow-night-eighties.min.css" />




<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


<meta name="generator" content="Hexo 4.2.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>


<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Bill Ma's Blog</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">
              <i class="iconfont icon-home-fill"></i>
              首页</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">
              <i class="iconfont icon-archive-fill"></i>
              归档</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">
              <i class="iconfont icon-category-fill"></i>
              分类</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">
              <i class="iconfont icon-tags-fill"></i>
              标签</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">
              <i class="iconfont icon-user-fill"></i>
              关于</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
                <div class="mt-3 post-meta">
                  <i class="iconfont icon-date-fill" aria-hidden="true"></i>
                  <time datetime="2020-06-25 22:10">
                    星期四, 六月 25日 2020, 10:10 晚上
                  </time>
                </div>
              

              <div class="mt-1">
                
                  
                  <span class="post-meta mr-2">
                    <i class="iconfont icon-chart"></i>
                    1.1k 字
                  </span>
                

                
                  
                  <span class="post-meta mr-2">
                      <i class="iconfont icon-clock-fill"></i>
                    
                    
                    22
                     分钟
                  </span>
                

                
              </div>
            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
            <article class="markdown-body">
              <p>Local binary patterns (LBP) is a type of visual descriptor used for classification in computer vision. LBP is the particular case of the Texture Spectrum model proposed in 1990. LBP was first described in 1994. It has since been found to be a powerful feature for texture classification; it has further been determined that when LBP is combined with the Histogram of oriented gradients (HOG) descriptor, it improves the detection performance considerably on some datasets. A comparison of several improvements of the original LBP in the field of background subtraction was made in 2015 by Silva et al. A full survey of the different versions of LBP can be found in Bouwmans et al.</p>
<!-- TODO: Modify above -->
<p><em>Note</em> Descriptors are the first step to find out the connection between pixels contained in a digital image and what humans recall after having observed an image or a group of images after some minutes.</p>
<!-- TODO: Modify above -->
<p>They can contain general information like colour, shape, textures and motion. Also, it can be trained to process information in some specific domain, like face recognition.</p>
<p><em>Note</em> The histogram of oriented gradients (HOG) is a feature descriptor used in computer vision and image processing for the purpose of object detection. The technique counts occurrences of gradient orientation in localised portions of an image. It is computed on a dense grid of uniformly spaced cells and uses overlapping local contrast normalisation for improved accuracy. The essential thought behind the histogram of oriented gradients descriptor is that local object appearance and shape within an image can be described by the distribution of intensity gradients or edge directions. The image is divided into small connected regions called cells, and for the pixels within each cell, a histogram of gradient directions is compiled. The descriptor is the concatenation of these histograms. For improved accuracy, the local histograms can be contrast-normalised by calculating a measure of the intensity across a larger region of the image, called a block, and then using this value to normalise all cells within the block. This normalisation results in better invariance to changes in illumination and shadowing.</p>
<!-- TODO: Modify above -->
<p>This post is split into three sections:</p>
<ol>
<li>The Basic Principles of LBP</li>
<li>Practice with OpenCV in Python</li>
<li>Compute LBP From Scratch</li>
</ol>
<p>Source code: <a href="https://github.com/BillMaZengou/cv_basis" target="_blank" rel="noopener">https://github.com/BillMaZengou/cv_basis</a> -&gt; <a href="http://lbp.py" target="_blank" rel="noopener">lbp.py</a> (OpenCV)</p>
<hr />
<h1 id="the-basic-principles-of-lbp"><a class="markdownIt-Anchor" href="#the-basic-principles-of-lbp"></a> The Basic Principles of LBP</h1>
<p>The basic idea for developing the LBP operator was that two-dimensional surface textures can be described by two complementary measures: local spatial patterns and grey scale contrast.</p>
<!-- TODO: Modify above -->
<p>The LBP operator originally used \(3 \cross 3\) neighbourhood of each pixel and consider the result as a binary number. (\(0\) or \(1\))</p>
<p>The LBP operator was extended to use neighbourhood of different sizes (Ojala et al. 2002). Using a circular neighbourhood and bilinearly interpolating values at non-integer pixel coordinates allow any radius and number of pixels in the neighbourhood.</p>
<!-- TODO: Modify above -->
<p><strong>Six properties of good features</strong></p>
<ol>
<li>Local: features are local, robust to occlusion and clutter. (i.e. no prior segmentation required)</li>
<li>Accurate: precise localisation.</li>
<li>Invariant (or covariant)</li>
<li>Robust: noise, blur, compression, etc. do not have a big impact on the feature.</li>
<li>Distinctive: individual features can be matched to a large database of objects.</li>
<li>Efficient: close to real-time performance.</li>
</ol>
<p>The properties 3. and 4. make the detector repeatable across multiple images.</p>
<p>Therefore, a natural selection of our interest points is the corners. Corners are locations where variations of intensity function \(f(x, y)\) in both \(x\) and \(y\) directions are high. (i.e. the partial derivatives of \(f(x, y)\) with respect to \(x\) and \(y\) are large)</p>
<p>On the contrast, for an edge, the partial derivative is large in only a certain direction; for a flat surface, the partial derivatives are small in both directions.</p>
<p>Harris corner detector uses these properties. Consider a small window (a kernel) on each pixel, and compute the partial derivatives by moving the kernel.<br />
<img src="harris.png" srcset="/img/loading.gif" alt="harris" /></p>
<p><strong>The Algorithm</strong><br />
<img src="step.png" srcset="/img/loading.gif" alt="steps" /></p>
<ol>
<li>For each pixel in the input image, the corner operator is applied to obtain a <em>cornerness</em> measure for this pixel.</li>
<li><em>Threshold cornerness map</em> to eliminate weak corners.</li>
<li>Apply <em>non-maximal suppression</em> to eliminate points whose cornerness measure is not larger than the cornerness values of all points within a certain distance.</li>
</ol>
<p>Mathematically, the change of intensity for the shift \([u, v]\) can be expressed as</p>
<p>Different \(R\) values can categorise a feature into flat surfaces, edges and corners.<br />
<img src="r.png" srcset="/img/loading.gif" alt="cate" /></p>
<p>Normally, it follows this pattern.<br />
<img src="harrisClass.png" srcset="/img/loading.gif" alt="class" /></p>
<p>The properties of Harris Corner Detector were studied.<br />
<img src="properties.png" srcset="/img/loading.gif" alt="property" /><br />
It is clear that Harris is invariant under the rotation but <strong>not</strong> invariant after scaling up.</p>
<hr />
<h1 id="practice-with-opencv-in-python"><a class="markdownIt-Anchor" href="#practice-with-opencv-in-python"></a> Practice with OpenCV in Python</h1>
<h3 id="documentation"><a class="markdownIt-Anchor" href="#documentation"></a> Documentation</h3>
<p>In OpenCV, we can use <code>cv2.cornerHarris</code> to implement a Harris corner detector.</p>
<pre class="highlight"><code class="">dst = cv2.cornerHarris(src, blockSize, ksize, k, borderType=BORDER_DEFAULT)
</code></pre>
<p><strong>src</strong> -&gt; (compulsory) Input single-channel 8-bit or floating-point image.<br />
<strong>dst</strong> -&gt; Image to store the Harris detector responses.<br />
<strong>blockSize</strong> -&gt; (compulsory) Neighbourhood size.<br />
<strong>ksize</strong> -&gt; (compulsory) Aperture parameter for the Sobel operator. For more information about the Sobel operator, check <strong>Computer Vision Foundation -&gt; Image Processing6: Edge Detection</strong>.<br />
<strong>k</strong> -&gt; (compulsory) Harris detector free parameter.<br />
<strong>borderType</strong> -&gt; (optional) Pixel extrapolation method. <em>BORDER_WRAP</em> is not supported. The default option is <em>BORDER_DEFAULT</em>.</p>
<p><em>Note</em> In OpenCV, <code>borderType</code> has<br />
<code>cv2.BORDER_CONSTANT</code> -&gt;    <code>iiiiii|abcdefgh|iiiiiii</code> with a specific <code>i</code><br />
<code>cv2.BORDER_REPLICATE</code> -&gt;   <code>aaaaaa|abcdefgh|hhhhhhh</code><br />
<code>cv2.BORDER_REFLECT</code> -&gt;     <code>fedcba|abcdefgh|hgfedcb</code><br />
<code>cv2.BORDER_WRAP</code> -&gt;        <code>cdefgh|abcdefgh|abcdefg</code><br />
<code>cv2.BORDER_REFLECT_101</code> -&gt; <code>gfedcb|abcdefgh|gfedcba</code><br />
<code>cv2.BORDER_TRANSPARENT</code> -&gt; <code>uvwxyz|abcdefgh|ijklmno</code></p>
<p><code>cv2.BORDER_DEFAULT</code> is as the same as <code>cv2.BORDER_REFLECT_101</code>.</p>
<h3 id="implementation"><a class="markdownIt-Anchor" href="#implementation"></a> Implementation</h3>
<pre class="highlight"><code class="">import cv2

# detector parameters
block_size = 3
sobel_size = 3
k = 0.06

name = image_name
img = cv2.imread('./{}.jpg'.format(name), cv2.IMREAD_UNCHANGED)
img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
# modify the data type setting to 32-bit floating point
img = np.float32(img)

# detect the corners with appropriate values as input parameters
corners_img = cv2.cornerHarris(img, block_size, sobel_size, k)

#result is dilated for marking the corners, not important
dst = cv2.dilate(dst, None)

# Threshold for an optimal value, marking the corners in Green
image[corners_img&gt;0.01*dst.max()] = [0,255,0]

cv2.imshow('Harris Corner Detector',image)
cv2.waitKey(0)
cv2.destroyAllWindows()
</code></pre>
<p>Example results are shown below:<br />
<strong>Original image</strong><br />
<img src="train.jpg" srcset="/img/loading.gif" alt="train" /></p>
<p><strong>Interest Points</strong><br />
<img src="train_interest_points.jpg" srcset="/img/loading.gif" alt="corner" /></p>
<p><em>Note</em> More details about <code>cv2.dilate</code>, please conduct <em><a href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.html" target="_blank" rel="noopener">https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.html</a></em></p>
<hr />
<h1 id="compute-lbp-from-scratch-todo"><a class="markdownIt-Anchor" href="#compute-lbp-from-scratch-todo"></a> Compute LBP From Scratch (TODO)</h1>
<hr />
<h1 id="acknowledgement"><a class="markdownIt-Anchor" href="#acknowledgement"></a> Acknowledgement</h1>
<p>The creation of this post is inspired by <strong>Datawhale</strong>.</p>
<hr />
<h1 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h1>
<ol>
<li><a href="http://En.wikipedia.org" target="_blank" rel="noopener">En.wikipedia.org</a>. 2020. Local Binary Patterns. [online] Available at: <a href="https://en.wikipedia.org/wiki/Local_binary_patterns#:~:text=Local%20binary%20patterns%20(LBP)%20is,was%20first%20described%20in%201994." target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Local_binary_patterns#:~:text=Local binary patterns (LBP) is,was first described in 1994.</a> [Accessed 25 June 2020].</li>
<li><a href="http://En.wikipedia.org" target="_blank" rel="noopener">En.wikipedia.org</a>. 2020. Visual Descriptor. [online] Available at: <a href="https://en.wikipedia.org/wiki/Visual_descriptor" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Visual_descriptor</a> [Accessed 25 June 2020].</li>
<li><a href="http://En.wikipedia.org" target="_blank" rel="noopener">En.wikipedia.org</a>. 2020. Histogram Of Oriented Gradients. [online] Available at: <a href="https://en.wikipedia.org/wiki/Histogram_of_oriented_gradients" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Histogram_of_oriented_gradients</a> [Accessed 26 June 2020].</li>
<li>PietikÃ¤inen, M., 2010. Local Binary Patterns. Scholarpedia, 5(3), p.9775.</li>
</ol>
<hr />

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/Computer/">Computer</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://zh.wikipedia.org/wiki/Wikipedia:CC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" target="_blank" rel="nofollow noopener noopener">CC BY-SA 3.0协议</a> 。转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                      <a href="/2020/06/27/NLP2-Word-Vectors-Algorithm-and-Analysis/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Natural Language Processing2: Word Vectors -> Algorithm and Analysis</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2020/06/23/NLP1-Word-to-Vectors/">
                        <span class="hidden-mobile">Natural Language Processing1: Word To Vectors</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    

    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/main.js" ></script>


  <script  src="/js/lazyload.js" ></script>



  
  <script  src="https://cdn.staticfile.org/tocbot/4.10.0/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: '.post-content',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>





  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>






<!-- Plugins -->



  <script  src="https://cdn.staticfile.org/prettify/188.0.0/prettify.min.js" ></script>
  <script>
    $(document).ready(function () {
      $('pre').each(function () {
        const pre = $(this);
        if (pre.find('code.mermaid').length > 0) {
          return;
        }
        pre.addClass('prettyprint  linenums');
      });
      prettyPrint();
    })
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "Computer Vision Foundation 2: LBP Face Recognition&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>





  

  
    <!-- MathJax -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
          tex2jax: {
              inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
              processEscapes: true,
              skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
          }
      });
      MathJax.Hub.Register.StartupHook("End Jax",function () {
        var BROWSER = MathJax.Hub.Browser;
        var jax = "HTML-CSS";
        if (BROWSER.isMSIE && BROWSER.hasMathPlayer) jax = "NativeMML";
        return MathJax.Hub.setRenderer(jax);
      });
      MathJax.Hub.Queue(function() {
          var all = MathJax.Hub.getAllJax(), i;
          for(i=0; i < all.length; i += 1) {
              all[i].SourceElement().parentNode.className += ' has-jax';
          }
      });

    </script>

    <script  src="https://cdn.staticfile.org/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML" ></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

  














<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
