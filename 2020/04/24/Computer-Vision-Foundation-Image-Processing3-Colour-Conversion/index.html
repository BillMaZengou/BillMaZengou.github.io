<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="UCL MRes Virtual Reality; University of Warwick BSc Physics">
  <meta name="author" content="Zengou Ma">
  <meta name="keywords" content="">
  <title>Computer Vision Foundation -&gt; Image Processing3: Colour Conversion - Bill Ma&#39;s Blog</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/3.0.1/github-markdown.min.css" />

<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_9n5xqdrq0nc.css">



  <link  rel="stylesheet" href="/lib/prettify/tomorrow-night-eighties.min.css" />




<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


<meta name="generator" content="Hexo 4.2.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>


<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Bill Ma's Blog</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">
              <i class="iconfont icon-home-fill"></i>
              首页</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">
              <i class="iconfont icon-archive-fill"></i>
              归档</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">
              <i class="iconfont icon-category-fill"></i>
              分类</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">
              <i class="iconfont icon-tags-fill"></i>
              标签</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">
              <i class="iconfont icon-user-fill"></i>
              关于</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
                <div class="mt-3 post-meta">
                  <i class="iconfont icon-date-fill" aria-hidden="true"></i>
                  <time datetime="2020-04-24 08:55">
                    星期五, 四月 24日 2020, 8:55 早上
                  </time>
                </div>
              

              <div class="mt-1">
                
                  
                  <span class="post-meta mr-2">
                    <i class="iconfont icon-chart"></i>
                    1.7k 字
                  </span>
                

                
                  
                  <span class="post-meta mr-2">
                      <i class="iconfont icon-clock-fill"></i>
                    
                    
                    34
                     分钟
                  </span>
                

                
              </div>
            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
            <article class="markdown-body">
              <p>In this post, another basic image operation is explored - Colour conversion.</p>
<p>This post is split into four sections:</p>
<ol>
<li>The Basic Principles of Colour Conversion</li>
<li>Details of <em>RGB2GRAY</em> and <em>RGB2HSV</em> Functions and Their Inverse Functions</li>
<li>Practice with OpenCV in Python</li>
<li>Build <em>RGB2GRAY</em> and <em>RGB2HSV</em> Functions and Their Inverse Functions From Scratch</li>
</ol>
<p>OpenCV code: <a href="https://github.com/BillMaZengou/cv_basis" target="_blank" rel="noopener">https://github.com/BillMaZengou/cv_basis</a> -&gt; colour.py; gray.py (My <em>RGB2GRAY</em>, display using OpenCV)<br>Re-implementation code: <a href="https://github.com/BillMaZengou/cv_basis/my_opencv" target="_blank" rel="noopener">https://github.com/BillMaZengou/cv_basis/my_opencv</a> -&gt; grey.py (My <em>RGB2GRAY</em>)</p>
<hr>
<h1 id="The-Basic-Principles-of-Colour-Conversion"><a href="#The-Basic-Principles-of-Colour-Conversion" class="headerlink" title="The Basic Principles of Colour Conversion"></a>The Basic Principles of Colour Conversion</h1><h3 id="Greyscale"><a href="#Greyscale" class="headerlink" title="Greyscale"></a>Greyscale</h3><p>A greyscale image is one in which the value of each pixel represents an amount of light. In other words, it carries only intensity information. The contrast ranges from black at the weakest intensity to white at the strongest.</p>
<p>Although the conversion from RGB to grey image can easily be done, sadly there is no simple explanation. Compare the following images<br><img src="laptop_original.jpg" srcset="/img/loading.gif" alt="laptop"><br><img src="laptop_Mean_Grey.jpg" srcset="/img/loading.gif" alt="laptop_mean"><br><img src="laptop_RGB_to_Grey.jpg" srcset="/img/loading.gif" alt="laptop_grey"><br>The second one was obtained by <strong>averaging RGB channels</strong>. The third one was obtained using <strong>OpenCV</strong> standard, which will be introduced in later sessions.</p>
<p>The goal of the conversion is to find the balance point between human perception and computational ease.</p>
<h4 id="Perceptual-Luminance-preserving-Conversion-to-Greyscale"><a href="#Perceptual-Luminance-preserving-Conversion-to-Greyscale" class="headerlink" title="Perceptual Luminance-preserving Conversion to Greyscale"></a>Perceptual Luminance-preserving Conversion to Greyscale</h4><p>The best conversion should provide the greyscale image with the same luminance as the original colour image. Details can conduct (Grayscale, 2020, <a href="https://en.wikipedia.org/wiki/Grayscale" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Grayscale</a>).</p>
<p>In standard,<br>\[<br>Y_{linear} = 0.2126 R_{linear} + 0.7152 G_{linear} + 0.0722 B_{linear},<br>\]<br>where \(Y_{linear}\) denotes linear luminance, and \(R_{linear}\), \(G_{linear}\) and \(B_{linear}\) represent linear luminance of each colour channel respectively. These three coefficients are the intensity perception of a normal person with the definition of <em>sRGB</em>.<br><strong>Human vision is most sensitive to green, so this has the greatest coefficient value (0.7152), and least sensitive to blue, so this has the smallest coefficient (0.0722)</strong>.</p>
<p>However, for a typical RGB image, the colour channels do not store linear luminance. The RGB values are gamma-compressed. Details are in (Gamma correction, 2020, <a href="https://en.wikipedia.org/wiki/Gamma_correction" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Gamma_correction</a>). To simplify, psychophysics suggested that human perception of physical quantities are non-linear. Empirically, it follows Stevens’s power law. Hence, if an image is made without power law, then we will feel unnatural since it will not match to our observation by eyes. Gamma compression is a correction to make the image fit to the power law.</p>
<p>Solving power equations are computationally expensive. Therefore, the <em>RGB2GRAY</em> operation in everyday life is merely an approximation.</p>
<h3 id="HSV"><a href="#HSV" class="headerlink" title="HSV"></a>HSV</h3><p>Most of the digital displays produce colours by combining red, green, and blue light with various intensities. Red, green and blue are so-called RGB additive primary colours. The resulting mixtures in RGB colour space can reproduce a wide variety of colours called a <strong>gamut</strong>. Gamut, or colour gamut, is a <em>complete subset</em> of colours, shown below.<br><img src="gamut.png" srcset="/img/loading.gif" alt="gamut"><br><em>CIE 1931 xy chromaticity diagram</em> showing the gamut of the <em>sRGB</em> colour space (the triangle). The outer curved boundary is the monochromatic spectrum with wavelengths shown in nanometers labeled in blue. This image is drawn using sRGB, so colours outside the triangle cannot be accurately coloured. The <em>D65 white point</em> is shown in the centre, and the <em>Planckian locus</em> is shown with colour temperatures labeled in kelvins. D65 is not an ideal 6500-kelvin blackbody because it is based on atmospheric filtered daylight.</p>
<p>The problem is that using RGB to generate colour is not intuitive. For example, as shown in the figure below, changing from one orange to a less saturated orange requires to modified RGB by different amounts.<br><img src="colorchange.png" srcset="/img/loading.gif" alt="colour_change"></p>
<p>In the mid-1970s Alvy Ray Smith described the <strong>HSV</strong> model for computer display technology to accommodate more intuitive colour mixing models. These models were useful because they were not only more intuitive than raw RGB values, but also the conversions to and from RGB were extremely fast to compute. <strong>They could run in real time on the hardware of the 1970s</strong>.<br><img src="hsv.jpg" srcset="/img/loading.gif" alt="hsv"><br>HSV stands for “hue, saturation, value”. The model can be shown in a cone. To make them simple,</p>
<p>  Hue: The angle of a circle, which is the cross-section of the HSV cone. The degrees indicate different colours. By convention, Red is at \(0\), green is at \(120\), and blue is at \(240\).</p>
<p>  Saturation: The radius of a circle, which is the cross-section of the HSV cone. The lengths indicate different colourfulness.</p>
<p>  Value: The height of the HSV cone. The lengths indicate different brightness.</p>
<hr>
<h1 id="Details-of-Two-Main-Operations"><a href="#Details-of-Two-Main-Operations" class="headerlink" title="Details of Two Main Operations"></a>Details of Two Main Operations</h1><h3 id="RGB-lt-–-gt-Grey"><a href="#RGB-lt-–-gt-Grey" class="headerlink" title="RGB &lt;–&gt; Grey"></a>RGB &lt;–&gt; Grey</h3><p>The conversion from RGB to Grey image is<br>\[<br>Y = 0.299 R + 0.587 G + 0.114 B,<br>\]<br>where \(Y\) is the greyscale value, and \(R\), \(G\), \(B\) denotes RGB values for each channel respectively.<br>As mentioned previously, this equation is an approximation of the accurate conversion. The equation works for digital formats following <strong>Rec. 601</strong> (i.e. most digital standard definition formats).</p>
<p><em>Note</em> The \(Y\) is gamma compressed, thus we do not need to worry about the power law.</p>
<p>The conversion from Grey to RGB image is<br>\[<br>R = Y; G = Y; B = Y.<br>\]<br>This operation cannot produce a colourful image, but simply create a RGB image form.</p>
<h3 id="RGB-lt-–-gt-HSV"><a href="#RGB-lt-–-gt-HSV" class="headerlink" title="RGB &lt;–&gt; HSV"></a>RGB &lt;–&gt; HSV</h3><p>In case of 8-bit and 16-bit images, RGB values are converted to the floating-point format and scaled to fit the 0 to 1 range.<br>\[<br>V = \max{(R, G, B)}<br>\]<br>\[<br>S = \frac{V - \min{(R, G, B)}}{V} \space \space \mbox{if } V \neq 0<br>\]<br>\[<br>S = 0 \space \space \mbox{if } V = 0<br>\]<br>\[<br>H = \frac{60(G - B)}{V - \min{(R, G, B)}} \space \space \mbox{if } V = R<br>\]<br>\[<br>H = 120 + \frac{60(B - R)}{V - \min{(R, G, B)}} \space \space \mbox{if } V = G<br>\]<br>\[<br>H = 240 + \frac{60(R - G)}{V - \min{(R, G, B)}} \space \space \mbox{if } V = B<br>\]<br>If \(H &lt; 0\) then \(H = H + 360\). The output \(0 \leqslant V \leqslant 1\), \(0 \leqslant S \leqslant 1\), \(0 \leqslant H \leqslant 360\).</p>
<p>The final output of the HSV format depends on the image data types. By default, <code>CV_32F</code> is output.<br>  <code>CV_8U</code>: \(V = 255V\), \(S = 255S\), \(H = H/2\)<br>  <code>CV_16U</code>: \(V = -65535V\), \(S = -65535S\), \(H = -H\) (<em>currently not supported</em>)</p>
<hr>
<h1 id="Practice-with-OpenCV-in-Python"><a href="#Practice-with-OpenCV-in-Python" class="headerlink" title="Practice with OpenCV in Python"></a>Practice with OpenCV in Python</h1><h3 id="Documentation"><a href="#Documentation" class="headerlink" title="Documentation"></a>Documentation</h3><p>In OpenCV, a general function takes care of all colour conversions.</p>
<pre><code>dst = cv2.cvtColor(src, code[, dst[, dstCn]])</code></pre><p><strong>src</strong> -&gt; (compulsory) Source image. 8-bit unsigned (<code>CV_8U</code>), 16-bit unsigned (<code>CV_16U</code>), or single-precision floating-point (<code>CV_32F</code>).<br><strong>dst</strong> -&gt; Destination image.<br><strong>code</strong> -&gt; (compulsory) colour space conversion code.<br><strong>dstCn</strong> -&gt; (optional) number of channels in the destination image. If it is \(0\), <strong>dstCn</strong> is derived automatically from <strong>src</strong> and <strong>code</strong>.</p>
<p><em>Note</em> The default colour format in OpenCV is actually <strong>BGR</strong>!!<br>The conventional range for RGB channel values are:<br>  \(0\) to \(255\) for <code>CV_8U</code><br>  \(0\) to \(65535\) for <code>CV_16U</code><br>  \(0\) to \(1\) for <code>CV_32F</code><br>For linear transformation, the range does not matter. But it does for non-linear transformation.</p>
<p>The <strong>code</strong> that we care about are <code>CV_BGR2GRAY</code>, <code>CV_GRAY2BGR</code>, <code>CV_BGR2HSV</code> and <code>CV_HSV2BGR</code>.</p>
<h3 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h3><h4 id="RGB-lt-–-gt-Grey-1"><a href="#RGB-lt-–-gt-Grey-1" class="headerlink" title="RGB &lt;–&gt; Grey"></a>RGB &lt;–&gt; Grey</h4><pre><code>import cv2

name = image_name
img = cv2.imread(&#39;./{}.jpg&#39;.format(name), cv2.IMREAD_UNCHANGED)
cv2.imshow(&quot;Original image&quot;, img)

bgr2grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
grey2bgr = cv2.cvtColor(bgr2grey, cv2.COLOR_GRAY2BGR)

cv2.imshow(&quot;BGR to Grey image&quot;, bgr2grey)
cv2.imshow(&quot;Grey to RGB image&quot;, grey2bgr)

print(bgr2grey.shape)
print(grey2bgr.shape)

cv2.waitKey(0)
cv2.destroyAllWindows()</code></pre><p>Example results are shown below:<br><strong>The original image</strong> (From <em>Image Processing1</em> post)<br><img src="flower_original.jpg" srcset="/img/loading.gif" alt="small"></p>
<p><strong>RGB_to_Grey</strong><br><img src="flower_RGB_to_Grey.jpg" srcset="/img/loading.gif" alt="c2g"></p>
<p><strong>Grey_to_RGB</strong><br><img src="flower_Grey_to_RGB.jpg" srcset="/img/loading.gif" alt="g2c"></p>
<p><em>Note</em> The <strong>Grey_to_RGB</strong> cannot recover the original image as expected. The information of RGB values has lost. The reason of using this function is to change the dimension of the grey image.</p>
<p>In our case, <strong>RGB_to_Grey</strong> has dimension \((530 \times 742)\), but <strong>Grey_to_RGB</strong> has dimension \((530 \times 742 \times 3)\).</p>
<h4 id="RGB-lt-–-gt-HSV-1"><a href="#RGB-lt-–-gt-HSV-1" class="headerlink" title="RGB &lt;–&gt; HSV"></a>RGB &lt;–&gt; HSV</h4><pre><code>import cv2

name = image_name
img = cv2.imread(&#39;./{}.jpg&#39;.format(name), cv2.IMREAD_UNCHANGED)
cv2.imshow(&quot;Original image&quot;, img)

bgr2hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)
hsv2bgr = cv2.cvtColor(bgr2hsv, cv2.COLOR_HSV2BGR)

cv2.imshow(&quot;RGB to HSV image&quot;, bgr2hsv)
cv2.imshow(&quot;HSV to RGB image&quot;, hsv2bgr)

cv2.waitKey(0)
cv2.destroyAllWindows()</code></pre><p>Example results are shown below:<br><strong>RGB_to_HSV</strong><br><img src="flower_RGB_to_HSV.jpg" srcset="/img/loading.gif" alt="h2g"></p>
<p><strong>HSV_to_RGB</strong><br><img src="flower_HSV_to_RGB.jpg" srcset="/img/loading.gif" alt="g2h"></p>
<p><em>Note</em> The unnatural colour of the <strong>RGB_to_HSV</strong> is ascribed to the fact that we use RGB to display HSV. <strong>HSV_to_RGB</strong> recover the original image as expected.</p>
<hr>
<h1 id="Build-RGB2GRAY-and-RGB2HSV-Functions-From-Scratch"><a href="#Build-RGB2GRAY-and-RGB2HSV-Functions-From-Scratch" class="headerlink" title="Build RGB2GRAY and RGB2HSV Functions From Scratch"></a>Build <em>RGB2GRAY</em> and <em>RGB2HSV</em> Functions From Scratch</h1><h3 id="RGB2GRAY"><a href="#RGB2GRAY" class="headerlink" title="RGB2GRAY"></a><em>RGB2GRAY</em></h3><pre><code>import numpy as np

def bgr_to_gray(img):
    cols, rows, channels = img.shape
    gray = np.zeros((cols, rows))
    b = img[:, :, 0]
    g = img[:, :, 1]
    r = img[:, :, 2]

    gray[:, :] = 0.229*r + 0.587*g + 0.114*b
    return gray</code></pre><p>The output is shown as below.<br><strong>My function</strong><br><img src="My_flower_RGB_to_Grey.jpg" srcset="/img/loading.gif" alt="my_grey"><br><strong>OpenCV</strong><br><img src="flower_RGB_to_Grey.jpg" srcset="/img/loading.gif" alt="open_grey"></p>
<p>More example:<br><strong>Color Image</strong><br><img src="temp1.jpg" srcset="/img/loading.gif" alt="pixel"><br><strong>Greyscale Image</strong><br><img src="tempG.jpg" srcset="/img/loading.gif" alt="pixel_grey"></p>
<p><em>Note</em> Some techniques can be applied to avoid floating point calculations.</p>
<h3 id="GRAY2RGB"><a href="#GRAY2RGB" class="headerlink" title="GRAY2RGB"></a><em>GRAY2RGB</em></h3><pre><code>def grey_to_rgb(img):
    if len(img.shape) != 2:
        print(&quot;Input should be a greyscale image&quot;)
    else:
        dst = np.zeros((img.shape[0], img.shape[1], 3))
        dst[:, :, 0] = img[:, :]
        dst[:, :, 1] = img[:, :]
        dst[:, :, 2] = img[:, :]
        return dst</code></pre><h3 id="RGB2HSV-TODO"><a href="#RGB2HSV-TODO" class="headerlink" title="RGB2HSV(TODO)"></a><em>RGB2HSV</em>(TODO)</h3><hr>
<h1 id="Acknowledgement"><a href="#Acknowledgement" class="headerlink" title="Acknowledgement"></a>Acknowledgement</h1><p>The creation of this post is inspired by <strong>Datawhale</strong>.</p>
<hr>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol>
<li>Photo by Viktor Mogilat on Unsplash.</li>
<li>Smith, A.R., 1978. Color gamut transform pairs. ACM Siggraph Computer Graphics, 12(3), pp.12-19.</li>
<li>En.wikipedia.org. 2020. SRGB. [online] Available at: <a href="https://en.wikipedia.org/wiki/SRGB" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/SRGB</a> [Accessed 24 April 2020].</li>
<li>En.wikipedia.org. 2020. HSL And HSV. [online] Available at: <a href="https://en.wikipedia.org/wiki/HSL_and_HSV#cite_ref-Smith_13-1" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/HSL_and_HSV#cite_ref-Smith_13-1</a> [Accessed 24 April 2020].</li>
<li>Blog.csdn.net. 2020. 色彩转换系列之RGB格式与HSV格式互转原理及实现_人工智能_小武的博客-CSDN博客. [online] Available at: <a href="https://blog.csdn.net/weixin_40647819/article/details/92660320" target="_blank" rel="noopener">https://blog.csdn.net/weixin_40647819/article/details/92660320</a> [Accessed 24 April 2020].</li>
<li>Docs.opencv.org. 2020. Miscellaneous Image Transformations — Opencv 2.4.13.7 Documentation. [online] Available at: <a href="https://docs.opencv.org/2.4/modules/imgproc/doc/miscellaneous_transformations.html" target="_blank" rel="noopener">https://docs.opencv.org/2.4/modules/imgproc/doc/miscellaneous_transformations.html</a> [Accessed 24 April 2020].</li>
<li>Photo by Omid Armin on Unsplash</li>
<li>Docs.opencv.org. 2020. Opencv: Color Conversions. [online] Available at: <a href="https://docs.opencv.org/3.1.0/de/d25/imgproc_color_conversions.html" target="_blank" rel="noopener">https://docs.opencv.org/3.1.0/de/d25/imgproc_color_conversions.html</a> [Accessed 24 April 2020].</li>
<li>Tutorialspoint.com. 2020. Grayscale To RGB Conversion - Tutorialspoint. [online] Available at: <a href="https://www.tutorialspoint.com/dip/grayscale_to_rgb_conversion.htm" target="_blank" rel="noopener">https://www.tutorialspoint.com/dip/grayscale_to_rgb_conversion.htm</a> [Accessed 24 April 2020].</li>
<li>En.wikipedia.org. 2020. Grayscale. [online] Available at: <a href="https://en.wikipedia.org/wiki/Grayscale" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Grayscale</a> [Accessed 24 April 2020].</li>
<li>En.wikipedia.org. 2020. Gamma Correction. [online] Available at: <a href="https://en.wikipedia.org/wiki/Gamma_correction" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Gamma_correction</a> [Accessed 24 April 2020].</li>
<li>Stevens, S.S., 1957. On the psychophysical law. Psychological review, 64(3), p.153.</li>
</ol>
<hr>

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/Computer/">Computer</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://zh.wikipedia.org/wiki/Wikipedia:CC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" target="_blank" rel="nofollow noopener noopener">CC BY-SA 3.0协议</a> 。转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                      <a href="/2020/04/26/Computer-Vision-Foundation-Image-Processing4-Image-Filtering/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Computer Vision Foundation -> Image Processing4: Image Filtering</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2020/04/21/Computer-Vision-Fundation-Image-Processing2-Geometric-Transformation/">
                        <span class="hidden-mobile">Computer Vision Foundation -> Image Processing2: Geometric Transformation</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    

    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/main.js" ></script>


  <script  src="/js/lazyload.js" ></script>



  
  <script  src="https://cdn.staticfile.org/tocbot/4.10.0/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: '.post-content',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>





  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>






<!-- Plugins -->



  <script  src="https://cdn.staticfile.org/prettify/188.0.0/prettify.min.js" ></script>
  <script>
    $(document).ready(function () {
      $('pre').each(function () {
        const pre = $(this);
        if (pre.find('code.mermaid').length > 0) {
          return;
        }
        pre.addClass('prettyprint  linenums');
      });
      prettyPrint();
    })
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "Computer Vision Foundation -> Image Processing3: Colour Conversion&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>





  

  
    <!-- MathJax -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
          tex2jax: {
              inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
              processEscapes: true,
              skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
          }
      });
      MathJax.Hub.Register.StartupHook("End Jax",function () {
        var BROWSER = MathJax.Hub.Browser;
        var jax = "HTML-CSS";
        if (BROWSER.isMSIE && BROWSER.hasMathPlayer) jax = "NativeMML";
        return MathJax.Hub.setRenderer(jax);
      });
      MathJax.Hub.Queue(function() {
          var all = MathJax.Hub.getAllJax(), i;
          for(i=0; i < all.length; i += 1) {
              all[i].SourceElement().parentNode.className += ' has-jax';
          }
      });

    </script>

    <script  src="https://cdn.staticfile.org/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML" ></script>

  














<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body>
</html>
